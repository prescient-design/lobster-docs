{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c7272a",
   "metadata": {},
   "source": [
    "# Concept Interventions with CB-LBSTER\n",
    "\n",
    "This tutorial demonstrates how to perform concept interventions using the Concept Bottleneck LBSTER models. Concept interventions allow you to modify specific biological properties of protein sequences in a controlled manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7049ab9",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, ensure LBSTER is installed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb3aea",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ef0c4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fe7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lobster.model import LobsterCBMPMLM\n",
    "from lobster.concepts._utils import supported_biopython_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650e114",
   "metadata": {},
   "source": [
    "## Loading a Concept Bottleneck Model\n",
    "\n",
    "Let's load a pre-trained Concept Bottleneck Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520990d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a concept bottleneck model\n",
    "model_name = \"asalam91/cb_lobster_24M\"  # 24M parameter CB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = LobsterCBMPMLM(model_name)\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14590a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of available concepts\n",
    "print(f\"Total number of concepts: {len(model.concept_names)}\")\n",
    "print(\"Example concepts:\", model.concept_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa55a7",
   "metadata": {},
   "source": [
    "## Define Sample Sequences\n",
    "\n",
    "We'll use a few sample protein sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHGKKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTPAVHASLDKFLASVSTVLTSKYR\",  # Hemoglobin alpha\n",
    "    \"MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPKVKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFGKEFTPPVQAAYQKVVAGVANALAHKYH\",  # Hemoglobin beta\n",
    "    \"EQKLISEEDLMAMVKQTLNSNLQFIHFIQKLINSQISLLIGKLFKKFNARIAKISAKEELRKHIAEQLNREVDYLEAKYAKKNREEMRKLEKEISQIKEDLKKTVESLQAKIQDLSKKYPGADAKKMEEQRQQLEEQKNKLQAEIENLLNSIDHAKKLKEEIAQLQEEISQLEDENEKLRRDIENQKENNKLLEEELTKLQAENSSLRKELEALTERLQDLYESLKLKDDDAVN\",  # Tropomyosin\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a327f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "sequence_names = [\"Hemoglobin α\", \"Hemoglobin β\", \"Tropomyosin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f469d",
   "metadata": {},
   "source": [
    "## Analyzing Original Concepts\n",
    "\n",
    "First, let's analyze the concepts in the original sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178b9ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_concepts(model, sequences, device=\"cuda\"):\n",
    "    \"\"\"Extract concepts from sequences using the model.\"\"\"\n",
    "    concepts_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq in sequences:\n",
    "            # Tokenize and process the sequence\n",
    "            tokens = model.tokenizer(seq, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            # Get concepts\n",
    "            outputs = model.model(\n",
    "                input_ids=tokens[\"input_ids\"],\n",
    "                attention_mask=tokens[\"attention_mask\"],\n",
    "                inference=True\n",
    "            )\n",
    "            \n",
    "            # Extract the concepts\n",
    "            seq_concepts = outputs[\"concepts\"].cpu().numpy().squeeze()\n",
    "            concepts_list.append(seq_concepts)\n",
    "    \n",
    "    return np.array(concepts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract concepts from original sequences\n",
    "original_concepts = extract_concepts(model, sequences, device)\n",
    "print(f\"Concepts shape: {original_concepts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca7ce8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Display top 5 concepts for each sequence\n",
    "for i, seq_name in enumerate(sequence_names):\n",
    "    # Get the top 5 concept indices for this sequence\n",
    "    top_concept_indices = np.argsort(original_concepts[i])[-5:][::-1]\n",
    "    \n",
    "    # Display the top concepts and their values\n",
    "    print(f\"\\nTop concepts for {seq_name}:\")\n",
    "    for idx in top_concept_indices:\n",
    "        print(f\"  {model.concept_names[idx]}: {original_concepts[i][idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97beb1f5",
   "metadata": {},
   "source": [
    "## Concept Intervention\n",
    "\n",
    "Now, let's perform interventions on specific concepts. We'll modify a concept and see how it affects the generated sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182bb9c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def intervene_and_generate(model, sequence, concept_index, intervention_value, device=\"cuda\", p_mask=0.25):\n",
    "    \"\"\"Intervene on a concept and generate a new sequence.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Tokenize and process the sequence\n",
    "        tokens = model.tokenizer(sequence, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Create a masked version of the input\n",
    "        masked_tokens = model._mask_inputs(tokens[\"input_ids\"], p_mask=p_mask)\n",
    "        \n",
    "        # Get concepts from the original sequence\n",
    "        outputs = model.model(\n",
    "            input_ids=tokens[\"input_ids\"],\n",
    "            attention_mask=tokens[\"attention_mask\"],\n",
    "            inference=True\n",
    "        )\n",
    "        \n",
    "        # Get the original concepts\n",
    "        original_concepts = outputs[\"concepts\"]\n",
    "        \n",
    "        # Create a modified concept tensor\n",
    "        modified_concepts = original_concepts.clone()\n",
    "        modified_concepts[0, concept_index] = intervention_value\n",
    "        \n",
    "        # Generate with the modified concepts\n",
    "        logits = model.model(\n",
    "            input_ids=masked_tokens,\n",
    "            concepts=modified_concepts,\n",
    "            inference=True,\n",
    "            attention_mask=tokens[\"attention_mask\"]\n",
    "        )[\"logits\"]\n",
    "        \n",
    "        # Get the predicted tokens\n",
    "        pred_tokens = logits.argmax(dim=-1)\n",
    "        \n",
    "        # Create the new sequence using the masked tokens as a template\n",
    "        mask = (masked_tokens == model.tokenizer.mask_token_id).int()\n",
    "        new_tokens = (masked_tokens * (1 - mask)) + (pred_tokens * mask)\n",
    "        \n",
    "        # Decode to get the new sequence\n",
    "        new_sequence = model.tokenizer.decode(new_tokens[0]).replace(\" \", \"\")\n",
    "        \n",
    "        # Clean the sequence to include only valid amino acids\n",
    "        valid_aa = \"ARNDCQEGHILKMFPSTWYV\"\n",
    "        new_sequence = \"\".join([aa for aa in new_sequence if aa in valid_aa])\n",
    "        \n",
    "        return new_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695718b0",
   "metadata": {},
   "source": [
    "## Intervention Examples\n",
    "\n",
    "Let's try intervening on the \"helix_fraction\" concept for the hemoglobin alpha sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1567447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a sequence to modify\n",
    "sequence_idx = 0  # Hemoglobin alpha\n",
    "sequence = sequences[sequence_idx]\n",
    "sequence_name = sequence_names[sequence_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a757cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a concept to modify\n",
    "concept_name = \"helix_fraction\"\n",
    "concept_idx = model.concept_names.index(concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88364125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original {concept_name} for {sequence_name}: {original_concepts[sequence_idx][concept_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervene with different values\n",
    "intervention_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "generated_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1f0ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "for value in intervention_values:\n",
    "    new_seq = intervene_and_generate(model, sequence, concept_idx, value, device)\n",
    "    generated_sequences.append(new_seq)\n",
    "    print(f\"\\nIntervention value: {value}\")\n",
    "    print(f\"Generated sequence: {new_seq[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24241e34",
   "metadata": {},
   "source": [
    "## Analyzing the Effects of Interventions\n",
    "\n",
    "Let's analyze how the interventions affected the actual properties of the generated sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df201d14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_helix_fraction(sequence):\n",
    "    \"\"\"Calculate the helix fraction using BioPython.\"\"\"\n",
    "    try:\n",
    "        analysis = ProteinAnalysis(sequence)\n",
    "        helix, turn, sheet = analysis.secondary_structure_fraction()\n",
    "        return helix\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sequence: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9907572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actual helix fractions for original and generated sequences\n",
    "original_helix = calculate_helix_fraction(sequence)\n",
    "generated_helix = [calculate_helix_fraction(seq) for seq in generated_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24326499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOriginal {sequence_name} helix fraction: {original_helix:.4f}\")\n",
    "print(\"Helix fractions of generated sequences:\")\n",
    "for i, value in enumerate(intervention_values):\n",
    "    print(f\"  Intervention value {value}: {generated_helix[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a46379",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(intervention_values, generated_helix, 'o-', markersize=10, linewidth=2)\n",
    "plt.axhline(y=original_helix, color='r', linestyle='--', label=f'Original sequence ({original_helix:.4f})')\n",
    "plt.xlabel('Intervention value for helix_fraction', fontsize=12)\n",
    "plt.ylabel('Actual helix fraction of generated sequence', fontsize=12)\n",
    "plt.title(f'Effect of helix_fraction intervention on {sequence_name}', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b8b55",
   "metadata": {},
   "source": [
    "## Multi-Concept Intervention\n",
    "\n",
    "Now, let's try intervening on multiple concepts simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907716d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def multi_concept_intervene(model, sequence, concept_indices, intervention_values, device=\"cuda\", p_mask=0.25):\n",
    "    \"\"\"Intervene on multiple concepts and generate a new sequence.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Tokenize and process the sequence\n",
    "        tokens = model.tokenizer(sequence, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Create a masked version of the input\n",
    "        masked_tokens = model._mask_inputs(tokens[\"input_ids\"], p_mask=p_mask)\n",
    "        \n",
    "        # Get concepts from the original sequence\n",
    "        outputs = model.model(\n",
    "            input_ids=tokens[\"input_ids\"],\n",
    "            attention_mask=tokens[\"attention_mask\"],\n",
    "            inference=True\n",
    "        )\n",
    "        \n",
    "        # Get the original concepts\n",
    "        original_concepts = outputs[\"concepts\"]\n",
    "        \n",
    "        # Create a modified concept tensor\n",
    "        modified_concepts = original_concepts.clone()\n",
    "        for idx, value in zip(concept_indices, intervention_values):\n",
    "            modified_concepts[0, idx] = value\n",
    "        \n",
    "        # Generate with the modified concepts\n",
    "        logits = model.model(\n",
    "            input_ids=masked_tokens,\n",
    "            concepts=modified_concepts,\n",
    "            inference=True,\n",
    "            attention_mask=tokens[\"attention_mask\"]\n",
    "        )[\"logits\"]\n",
    "        \n",
    "        # Get the predicted tokens\n",
    "        pred_tokens = logits.argmax(dim=-1)\n",
    "        \n",
    "        # Create the new sequence using the masked tokens as a template\n",
    "        mask = (masked_tokens == model.tokenizer.mask_token_id).int()\n",
    "        new_tokens = (masked_tokens * (1 - mask)) + (pred_tokens * mask)\n",
    "        \n",
    "        # Decode to get the new sequence\n",
    "        new_sequence = model.tokenizer.decode(new_tokens[0]).replace(\" \", \"\")\n",
    "        \n",
    "        # Clean the sequence to include only valid amino acids\n",
    "        valid_aa = \"ARNDCQEGHILKMFPSTWYV\"\n",
    "        new_sequence = \"\".join([aa for aa in new_sequence if aa in valid_aa])\n",
    "        \n",
    "        return new_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose two concepts to modify simultaneously\n",
    "concept1_name = \"helix_fraction\"\n",
    "concept2_name = \"gravy\"  # hydrophobicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept1_idx = model.concept_names.index(concept1_name)\n",
    "concept2_idx = model.concept_names.index(concept2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original {concept1_name} for {sequence_name}: {original_concepts[sequence_idx][concept1_idx]:.4f}\")\n",
    "print(f\"Original {concept2_name} for {sequence_name}: {original_concepts[sequence_idx][concept2_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with high helix, low hydrophobicity\n",
    "high_helix_low_hydro = multi_concept_intervene(\n",
    "    model, sequence, [concept1_idx, concept2_idx], [0.9, 0.1], device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea5ad8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generate with low helix, high hydrophobicity  \n",
    "low_helix_high_hydro = multi_concept_intervene(\n",
    "    model, sequence, [concept1_idx, concept2_idx], [0.1, 0.9], device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e25b1f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "def calculate_gravy(sequence):\n",
    "    \"\"\"Calculate the GRAVY (hydrophobicity) using BioPython.\"\"\"\n",
    "    try:\n",
    "        analysis = ProteinAnalysis(sequence)\n",
    "        return analysis.gravy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sequence: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actual properties\n",
    "original_helix = calculate_helix_fraction(sequence)\n",
    "original_gravy = calculate_gravy(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897846ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_helix_low_hydro_helix = calculate_helix_fraction(high_helix_low_hydro)\n",
    "high_helix_low_hydro_gravy = calculate_gravy(high_helix_low_hydro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_helix_high_hydro_helix = calculate_helix_fraction(low_helix_high_hydro)\n",
    "low_helix_high_hydro_gravy = calculate_gravy(low_helix_high_hydro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee756d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMulti-concept intervention results:\")\n",
    "print(f\"Original sequence: Helix={original_helix:.4f}, GRAVY={original_gravy:.4f}\")\n",
    "print(f\"High helix, low hydro: Helix={high_helix_low_hydro_helix:.4f}, GRAVY={high_helix_low_hydro_gravy:.4f}\")\n",
    "print(f\"Low helix, high hydro: Helix={low_helix_high_hydro_helix:.4f}, GRAVY={low_helix_high_hydro_gravy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce451b1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've demonstrated how to:\n",
    "\n",
    "1. Load and use LBSTER's Concept Bottleneck Models\n",
    "2. Extract and analyze the concepts in protein sequences\n",
    "3. Perform single-concept interventions to modify specific properties\n",
    "4. Perform multi-concept interventions to simultaneously adjust multiple properties\n",
    "5. Analyze the effects of interventions on the actual properties of generated sequences\n",
    "\n",
    "Concept interventions provide a powerful tool for controlled protein sequence design, allowing you to target specific properties while maintaining the overall structure and function of the protein."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}