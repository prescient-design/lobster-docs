# LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation ðŸ¦ž

`lobster` is a "batteries included" language model library for molecular foundation models.
* Fast pre-training from scratch: LBSTER is built for pre-training models quickly from scratch with a "batteries included" approach. This is most useful if you need to control the pre-training data mixture and embedding space, or want to experiment with novel pre-training objectives and fine-tuning strategies.
* Built for real-world drug discovery: LBSTER is a living, open-source library that is periodically updated with new code and pre-trained models from the [Frey Lab: Foundation Models for Drug Discovery](https://ncfrey.github.io/) and Research Engineering at [Prescient Design, Genentech](https://www.gene.com/scientists/our-scientists/prescient-design). The Frey Lab works on real therapeutic molecule design problems and LBSTER models and capabilities reflect the demands of real-world drug discovery campaigns.
* Integrated ecosystem: LBSTER is built with beignet, a standard library for biological research, and integrated with cortex, a modular framework for multitask modeling, guided generation, and multi-modal models.
* Concept support: LBSTER supports concepts through its concept-bottleneck protein language model, CB-LBSTER, which supports 718 concepts for interpretable sequence modeling.

## Getting started
Follow the installation instructions in the `lobster` [README](https://github.com/prescient-design/lobster/tree/main?tab=readme-ov-file#install-) or in the [Installation Guide](installation.md)

## Citations
If you use `lobster` code and/or models, please cite the relevant papers in the `lobster` [README](https://github.com/prescient-design/lobster/tree/main?tab=readme-ov-file#citations-).

## Contributions
Contributions are welcome! See all the [lobster contributors](contributors.md).

<!-- ```{tableofcontents}
``` -->
