{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyAb Model: Training and Inference Tutorial\n",
    "# ====================================\n",
    "#\n",
    "# This notebook demonstrates how to use the DataFrameLightningDataModule with the DyAbModel\n",
    "# for training and performing inference on antibody data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Import the necessary lobster modules\n",
    "from lobster.data import DataFrameLightningDataModule, DyAbDataFrameLightningDataModule\n",
    "from lobster.model._utils import model_typer  # For loading pretrained models\n",
    "from lobster.tokenization import AminoAcidTokenizerFast\n",
    "from lobster.transforms import TokenizerTransform\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "pl.seed_everything(SEED, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Sample Dataset\n",
    "\n",
    "For this tutorial, we'll create a synthetic dataset to demonstrate the functionality.\n",
    "In real applications, you would use your own antibody data.\n",
    "\n",
    "The DyAb model is trained to predict the difference between properties (y1 - y2),\n",
    "so we need to create our data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(num_samples=500, seed=42):\n",
    "    \"\"\"Generate synthetic antibody data for demonstration with DyAb model.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create random heavy and light chain sequences\n",
    "    amino_acids = list(\"ARNDCEQGHILKMFPSTWYV\")\n",
    "    \n",
    "    heavy_lengths = np.random.randint(110, 130, num_samples)\n",
    "    light_lengths = np.random.randint(105, 115, num_samples)\n",
    "    \n",
    "    heavy_chains = []\n",
    "    light_chains = []\n",
    "    \n",
    "    for h_len, l_len in zip(heavy_lengths, light_lengths):\n",
    "        heavy = ''.join(np.random.choice(amino_acids, h_len))\n",
    "        light = ''.join(np.random.choice(amino_acids, l_len))\n",
    "        heavy_chains.append(heavy)\n",
    "        light_chains.append(light)\n",
    "    \n",
    "    # Create synthetic pKD values (binding affinity)\n",
    "    # For this toy example, we'll make longer sequences correlate with higher affinity\n",
    "    pkd_values = (heavy_lengths + light_lengths) / 40 + np.random.normal(0, 0.5, num_samples)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'fv_heavy': heavy_chains,\n",
    "        'fv_light': light_chains,\n",
    "        'pKD': pkd_values\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate sample data\n",
    "df = generate_sample_data(500)\n",
    "\n",
    "# Examine the data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up the DyAbDataFrameLightningDataModule\n",
    "\n",
    "The DyAb model expects data in the form of paired sequences with their corresponding\n",
    "target values, where during training it learns to predict the differences between pairs.\n",
    "\n",
    "Let's set up the data module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer transform\n",
    "tokenizer = AminoAcidTokenizerFast()\n",
    "transform_fn = TokenizerTransform(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=\"max_length\",\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True\n",
    ")\n",
    "\n",
    "# Initialize the DyAb datamodule\n",
    "dyab_datamodule = DyAbDataFrameLightningDataModule(\n",
    "    data=df,\n",
    "    remove_nulls=True,\n",
    "    transform_fn=transform_fn,\n",
    "    lengths=[0.8, 0.1, 0.1],  # Train, val, test split\n",
    "    batch_size=16,\n",
    "    seed=SEED,\n",
    "    num_workers=4,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# Set up the datamodule\n",
    "dyab_datamodule.prepare_data()\n",
    "dyab_datamodule.setup(stage=\"fit\")\n",
    "\n",
    "# Let's examine what a batch from the dataloader looks like\n",
    "train_dataloader = dyab_datamodule.train_dataloader()\n",
    "for batch in train_dataloader:\n",
    "    sequence1, sequence2, target1, target2 = batch\n",
    "    print(\"Sequence1 shape:\", sequence1[0].shape)  # First element of the tuple for heavy chain\n",
    "    print(\"Sequence2 shape:\", sequence2[0].shape)  # First element of the tuple for heavy chain\n",
    "    print(\"Target1 shape:\", target1.shape)\n",
    "    print(\"Target2 shape:\", target2.shape)\n",
    "    print(\"Target difference (what model will predict):\", (target1 - target2).mean().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the DyAb Model\n",
    "\n",
    "Now we'll initialize and train the DyAb model. We'll use the FlexBERT architecture\n",
    "which is designed to handle protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DyAb model\n",
    "model_config = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \n",
    "    # FlexBERT parameters\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_hidden_layers\": 4,\n",
    "    \"num_attention_heads\": 4,\n",
    "    \"intermediate_size\": 1024,\n",
    "    \"hidden_act\": \"gelu\",\n",
    "    \"attention_probs_dropout_prob\": 0.1,\n",
    "    \"hidden_dropout_prob\": 0.1,\n",
    "    \"vocab_size\": tokenizer.vocab_size,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \n",
    "    # Regression parameters\n",
    "    \"regressor_hidden_size\": 128,\n",
    "    \"regressor_num_layers\": 2,\n",
    "    \"regressor_dropout\": 0.1\n",
    "}\n",
    "\n",
    "# Import the DyAb model\n",
    "from lobster.model.dyab import DyAb\n",
    "\n",
    "# Initialize the model\n",
    "dyab_model = DyAb(\n",
    "    model_config=model_config,\n",
    "    learning_rate=model_config[\"lr\"],\n",
    "    tokenizer=\"amino_acid_tokenizer\",\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath='checkpoints/',\n",
    "        filename='dyab-{epoch:02d}-{val_loss:.4f}',\n",
    "        save_top_k=3,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        mode='min'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Now let's train the DyAb model using our datamodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(dyab_model, datamodule=dyab_datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model\n",
    "\n",
    "Let's evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_results = trainer.test(dyab_model, datamodule=dyab_datamodule)\n",
    "print(f\"Test results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Inference on New Sequences\n",
    "\n",
    "Now let's demonstrate how to use the trained model for inference on new antibody sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_binding_differences(model, new_data):\n",
    "    \"\"\"\n",
    "    Predict binding affinity differences for pairs of antibody sequences.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained DyAb model\n",
    "        new_data: DataFrame with fv_heavy, fv_light, pKD columns\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predicted differences\n",
    "    \"\"\"\n",
    "    # Create a datamodule for inference\n",
    "    inference_datamodule = DyAbDataFrameLightningDataModule(\n",
    "        data=new_data,\n",
    "        remove_nulls=True,\n",
    "        transform_fn=transform_fn,\n",
    "        lengths=[0, 0, 1],  # All data for inference\n",
    "        batch_size=16,\n",
    "        seed=SEED,\n",
    "        num_workers=4,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Set up the datamodule\n",
    "    inference_datamodule.prepare_data()\n",
    "    inference_datamodule.setup(stage=\"predict\")\n",
    "    \n",
    "    # Perform inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    sequence1_data = []\n",
    "    sequence2_data = []\n",
    "    actual_diffs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in inference_datamodule.predict_dataloader():\n",
    "            sequence1, sequence2, target1, target2 = batch\n",
    "            \n",
    "            # Process through the model\n",
    "            pred_diff = model(sequence1, sequence2)\n",
    "            actual_diff = (target1 - target2).cpu().numpy()\n",
    "            \n",
    "            predictions.extend(pred_diff.cpu().numpy())\n",
    "            actual_diffs.extend(actual_diff)\n",
    "            \n",
    "            # Store sequence information for reference\n",
    "            for i in range(len(target1)):\n",
    "                sequence1_data.append({\n",
    "                    \"heavy\": sequence1[0][i],\n",
    "                    \"light\": sequence1[1][i],\n",
    "                    \"target\": target1[i].item()\n",
    "                })\n",
    "                sequence2_data.append({\n",
    "                    \"heavy\": sequence2[0][i],\n",
    "                    \"light\": sequence2[1][i],\n",
    "                    \"target\": target2[i].item()\n",
    "                })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        \"Predicted_Difference\": predictions,\n",
    "        \"Actual_Difference\": actual_diffs,\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate some new sequences for inference\n",
    "new_data = generate_sample_data(20, seed=100)\n",
    "\n",
    "# Predict binding affinity differences\n",
    "results_df = predict_binding_differences(dyab_model, new_data)\n",
    "\n",
    "# Display results\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions vs. Actual Differences\n",
    "\n",
    "Let's visualize how well our model's predictions match the actual differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted differences\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(results_df[\"Actual_Difference\"], results_df[\"Predicted_Difference\"], alpha=0.7)\n",
    "plt.plot(\n",
    "    [min(results_df[\"Actual_Difference\"]), max(results_df[\"Actual_Difference\"])], \n",
    "    [min(results_df[\"Actual_Difference\"]), max(results_df[\"Actual_Difference\"])], \n",
    "    'r--'\n",
    ")\n",
    "plt.xlabel('Actual Difference')\n",
    "plt.ylabel('Predicted Difference')\n",
    "plt.title('Predicted vs. Actual Affinity Differences')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(results_df[\"Actual_Difference\"], results_df[\"Predicted_Difference\"])\n",
    "print(f\"R² score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using the Model for Ranking Antibodies\n",
    "\n",
    "One valuable application of the DyAb model is to rank antibodies based on predicted affinities.\n",
    "Let's demonstrate how to use the model for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_antibodies(model, antibody_pool, reference_antibody):\n",
    "    \"\"\"\n",
    "    Rank a pool of antibodies against a reference antibody based on predicted binding affinity.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained DyAb model\n",
    "        antibody_pool: DataFrame with fv_heavy, fv_light, pKD columns for candidate antibodies\n",
    "        reference_antibody: Dict with fv_heavy, fv_light for the reference antibody\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with ranked antibodies\n",
    "    \"\"\"\n",
    "    # Create pairs of reference and candidate antibodies\n",
    "    pairs_data = []\n",
    "    \n",
    "    for _, candidate in antibody_pool.iterrows():\n",
    "        pairs_data.append({\n",
    "            \"fv_heavy\": reference_antibody[\"fv_heavy\"],\n",
    "            \"fv_light\": reference_antibody[\"fv_light\"],\n",
    "            \"pKD\": 0.0,  # Dummy value for reference\n",
    "            \"candidate_heavy\": candidate[\"fv_heavy\"],\n",
    "            \"candidate_light\": candidate[\"fv_light\"],\n",
    "            \"candidate_pKD\": candidate[\"pKD\"]\n",
    "        })\n",
    "    \n",
    "    pairs_df = pd.DataFrame(pairs_data)\n",
    "    \n",
    "    # Create a combined dataset for DyAb format\n",
    "    # We need to duplicate each row and swap the order to get predictions in both directions\n",
    "    combined_data = []\n",
    "    \n",
    "    for _, row in pairs_df.iterrows():\n",
    "        # Reference first, candidate second\n",
    "        combined_data.append({\n",
    "            \"fv_heavy\": row[\"fv_heavy\"],\n",
    "            \"fv_light\": row[\"fv_light\"],\n",
    "            \"pKD\": row[\"pKD\"]\n",
    "        })\n",
    "        \n",
    "        # Candidate first, reference second\n",
    "        combined_data.append({\n",
    "            \"fv_heavy\": row[\"candidate_heavy\"],\n",
    "            \"fv_light\": row[\"candidate_light\"],\n",
    "            \"pKD\": row[\"candidate_pKD\"]\n",
    "        })\n",
    "    \n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "    \n",
    "    # Create a datamodule\n",
    "    inference_datamodule = DyAbDataFrameLightningDataModule(\n",
    "        data=combined_df,\n",
    "        remove_nulls=True,\n",
    "        transform_fn=transform_fn,\n",
    "        lengths=[0, 0, 1],  # All data for inference\n",
    "        batch_size=16,\n",
    "        seed=SEED,\n",
    "        num_workers=4,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Set up the datamodule\n",
    "    inference_datamodule.prepare_data()\n",
    "    inference_datamodule.setup(stage=\"predict\")\n",
    "    \n",
    "    # Perform inference\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in inference_datamodule.predict_dataloader():\n",
    "            sequence1, sequence2, target1, target2 = batch\n",
    "            pred_diff = model(sequence1, sequence2)\n",
    "            all_preds.extend(pred_diff.cpu().numpy())\n",
    "    \n",
    "    # Process predictions (every second prediction is for ref-candidate pair)\n",
    "    ref_candidate_preds = all_preds[::2]\n",
    "    \n",
    "    # Add predictions to the original dataframe\n",
    "    for i, pred in enumerate(ref_candidate_preds):\n",
    "        pairs_df.loc[i, \"predicted_diff_ref_candidate\"] = pred\n",
    "    \n",
    "    # Sort by prediction (higher predicted difference means candidate is better than reference)\n",
    "    ranked_df = pairs_df.sort_values(by=\"predicted_diff_ref_candidate\", ascending=False)\n",
    "    \n",
    "    # Add rank column\n",
    "    ranked_df[\"rank\"] = range(1, len(ranked_df) + 1)\n",
    "    \n",
    "    return ranked_df[[\"rank\", \"candidate_heavy\", \"candidate_light\", \"candidate_pKD\", \"predicted_diff_ref_candidate\"]]\n",
    "\n",
    "# Generate a pool of candidate antibodies\n",
    "candidate_pool = generate_sample_data(50, seed=200)\n",
    "\n",
    "# Select a reference antibody\n",
    "reference_antibody = {\n",
    "    \"fv_heavy\": df.iloc[0][\"fv_heavy\"],\n",
    "    \"fv_light\": df.iloc[0][\"fv_light\"]\n",
    "}\n",
    "\n",
    "# Rank antibodies\n",
    "ranked_candidates = rank_antibodies(dyab_model, candidate_pool, reference_antibody)\n",
    "\n",
    "# Display top 10 ranked antibodies\n",
    "print(\"Top 10 Ranked Antibodies:\")\n",
    "print(ranked_candidates.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving and Loading the Model\n",
    "\n",
    "Demonstrating how to save and load a trained DyAb model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"dyab_model.ckpt\"\n",
    "trainer.save_checkpoint(model_path)\n",
    "\n",
    "# Load the model\n",
    "loaded_model = DyAb.load_from_checkpoint(model_path)\n",
    "\n",
    "# Verify the loaded model\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a batch from the dataloader\n",
    "    for batch in dyab_datamodule.val_dataloader():\n",
    "        sequence1, sequence2, target1, target2 = batch\n",
    "        \n",
    "        # Make predictions with both models\n",
    "        original_pred = dyab_model(sequence1, sequence2)\n",
    "        loaded_pred = loaded_model(sequence1, sequence2)\n",
    "        \n",
    "        # Verify they give the same predictions\n",
    "        print(\"Original model prediction mean:\", original_pred.mean().item())\n",
    "        print(\"Loaded model prediction mean:\", loaded_pred.mean().item())\n",
    "        \n",
    "        # Check if predictions are identical\n",
    "        is_identical = torch.allclose(original_pred, loaded_pred, atol=1e-5)\n",
    "        print(f\"Models give identical predictions: {is_identical}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this tutorial, we've demonstrated how to:\n",
    "\n",
    "1. Prepare antibody data for the DyAb model\n",
    "2. Train a DyAb model using DataFrameLightningDataModule\n",
    "3. Evaluate the model's performance\n",
    "4. Use the model for inference and ranking of antibodies\n",
    "5. Save and load the model\n",
    "\n",
    "The DyAb model is particularly useful for learning pairwise relationships between sequences,\n",
    "which makes it valuable for tasks like antibody optimization, where you want to predict if\n",
    "a modification to a sequence will improve its properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
