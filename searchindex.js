Search.setIndex({"alltitles": {"": [[6, "id2"]], "1. Amino Acid Tokenizer": [[4, "amino-acid-tokenizer"]], "1. Create a Sample Dataset": [[6, "create-a-sample-dataset"]], "1. Masked Language Models (LobsterPMLM)": [[3, "masked-language-models-lobsterpmlm"]], "10. Conclusion": [[6, "conclusion"]], "2. Concept Bottleneck Models (LobsterCBMPMLM)": [[3, "concept-bottleneck-models-lobstercbmpmlm"]], "2. Nucleotide Tokenizer": [[4, "nucleotide-tokenizer"]], "2. Set Up the DyAbDataFrameLightningDataModule": [[6, "set-up-the-dyabdataframelightningdatamodule"]], "3. Causal Language Models (LobsterPCLM)": [[3, "causal-language-models-lobsterpclm"]], "3. SMILES Tokenizer": [[4, "smiles-tokenizer"]], "3. Using the DyAb Model": [[6, "using-the-dyab-model"]], "4. PMLM Tokenizer": [[4, "pmlm-tokenizer"]], "4. Structure Prediction Models (LobsterPLMFold)": [[3, "structure-prediction-models-lobsterplmfold"]], "4. Train the Model": [[6, "train-the-model"]], "5. Evaluate the Model": [[6, "evaluate-the-model"]], "5. MGM Tokenizer": [[4, "mgm-tokenizer"]], "6. Perform Inference on New Sequences": [[6, "perform-inference-on-new-sequences"]], "7. Visualize Predictions vs. Actual Differences": [[6, "visualize-predictions-vs-actual-differences"]], "8. Using the Model for Ranking Antibodies": [[6, "using-the-model-for-ranking-antibodies"]], "9. Saving and Loading the Model": [[6, "saving-and-loading-the-model"]], "====================================": [[6, "id1"]], "Advanced: Training Strategies for Production Models": [[8, "advanced-training-strategies-for-production-models"]], "Analyzing Original Concepts": [[5, "analyzing-original-concepts"]], "Analyzing Top Concepts": [[7, "analyzing-top-concepts"]], "Analyzing the Effects of Interventions": [[5, "analyzing-the-effects-of-interventions"]], "Basic Tokenizer Transform": [[4, "basic-tokenizer-transform"]], "Basic inference:": [[3, "basic-inference"]], "Citations": [[2, "citations"]], "Concept Bottleneck Models": [[3, "concept-bottleneck-models"]], "Concept Intervention": [[5, "concept-intervention"]], "Concept Interventions with CB-LBSTER": [[5, null]], "Concept-aware Tokenizer Transform": [[4, "concept-aware-tokenizer-transform"]], "Conclusion": [[5, "conclusion"], [7, "conclusion"], [8, "conclusion"]], "Contributions": [[2, "contributions"]], "Contributors": [[0, null]], "Custom Tokenization Workflows": [[4, "custom-tokenization-workflows"]], "Define Sample Sequences": [[5, "define-sample-sequences"]], "Dependencies": [[1, "dependencies"]], "DyAb Model: Training and Inference Tutorial": [[6, null]], "Embedding Extraction with LBSTER": [[7, null]], "Extracting Embeddings": [[7, "extracting-embeddings"]], "GPU Support": [[1, "gpu-support"]], "Getting started": [[2, "getting-started"]], "Installation": [[1, null]], "Installing Optional Dependencies": [[1, "installing-optional-dependencies"]], "Intervention Examples": [[5, "intervention-examples"]], "LBSTER Models Overview": [[3, null]], "LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation \ud83e\udd9e": [[2, null]], "Loading a Concept Bottleneck Model": [[5, "loading-a-concept-bottleneck-model"]], "Loading a Pre-trained Model": [[7, "loading-a-pre-trained-model"]], "Loading a pre-trained model:": [[3, "loading-a-pre-trained-model"]], "Masked Language Models": [[3, "masked-language-models"]], "Model Architectures": [[3, "model-architectures"]], "Model Selection Guide": [[3, "model-selection-guide"]], "Multi-Concept Intervention": [[5, "multi-concept-intervention"]], "Pre-trained Models": [[3, "pre-trained-models"]], "Sample Protein Sequences": [[7, "sample-protein-sequences"]], "Setup and Installation": [[5, "setup-and-installation"], [7, "setup-and-installation"], [8, "setup-and-installation"]], "Special Tokens": [[4, "special-tokens"]], "Step 1: Prepare Your Data": [[8, "step-1-prepare-your-data"]], "Step 2: Create a Configuration File": [[8, "step-2-create-a-configuration-file"]], "Step 3: Model Configuration": [[8, "step-3-model-configuration"]], "Step 4: Training Process": [[8, "step-4-training-process"]], "Step 5: Simulated Training Process": [[8, "step-5-simulated-training-process"]], "Step 6: Model Evaluation": [[8, "step-6-model-evaluation"]], "Step 7: Using Your Trained Model": [[8, "step-7-using-your-trained-model"]], "This notebook demonstrates how to use the DataFrameLightningDataModule with the DyAbModel": [[6, "this-notebook-demonstrates-how-to-use-the-dataframelightningdatamodule-with-the-dyabmodel"]], "Tokenization in LBSTER": [[4, null]], "Tokenizer Transforms": [[4, "tokenizer-transforms"]], "Tokenizer Types": [[4, "tokenizer-types"]], "Training a LBSTER Model from Scratch": [[8, null]], "Troubleshooting": [[1, "troubleshooting"]], "Usage Examples": [[3, "usage-examples"]], "Using Concept Bottleneck Models": [[7, "using-concept-bottleneck-models"]], "Using Tokenizers with Models": [[4, "using-tokenizers-with-models"]], "Using mamba or conda": [[1, "using-mamba-or-conda"]], "Using uv": [[1, "using-uv"]], "Verifying Installation": [[1, "verifying-installation"]], "Visualizing Embeddings": [[7, "visualizing-embeddings"]], "Vocabulary Sizes": [[4, "vocabulary-sizes"]], "for training and performing inference on antibody data.": [[6, "for-training-and-performing-inference-on-antibody-data"]]}, "docnames": ["contributors", "installation", "intro", "models/overview", "tokenization/overview", "tutorials/concept_interventions", "tutorials/dyab", "tutorials/embedding_extraction", "tutorials/training_from_scratch"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["contributors.md", "installation.md", "intro.md", "models/overview.md", "tokenization/overview.md", "tutorials/concept_interventions.ipynb", "tutorials/dyab.ipynb", "tutorials/embedding_extraction.ipynb", "tutorials/training_from_scratch.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 6, 7, 8], "0": [1, 3, 4, 5, 6, 7, 8], "01": [6, 8], "02d": 6, "1": [5, 7], "10": [1, 5, 7, 8], "100": [6, 7, 8], "1000": 8, "100k": 8, "1024": 6, "105": 6, "11": 7, "110": 6, "115": 6, "12": [1, 4, 5, 6, 7, 8], "128": [6, 8], "13": 7, "130": 6, "14": [5, 7], "1468": 8, "15": [7, 8], "150m": 3, "16": [6, 7, 8], "16gb": 3, "17": 7, "19": 7, "1965": 8, "19680801": [], "1e": [6, 7, 8], "2": [5, 7], "20": [4, 6], "200": [6, 8], "2014": [], "2048": 7, "21": [6, 7, 8], "24": [1, 8], "24gb": 3, "24m": [3, 5, 7], "25": 5, "256": [6, 8], "29": 6, "2970": 8, "2f": 8, "3": [1, 5, 7], "30": [4, 6], "31": 6, "32": [6, 7], "33": [4, 6], "332247": 6, "35": 8, "3b": 3, "4": [1, 5], "40": [6, 8], "4009": 8, "408": 7, "42": 6, "433": 7, "434": 7, "435": 7, "4f": [5, 6, 7, 8], "4gb": 1, "5": [5, 7], "50": [5, 6, 8], "500": 6, "512": [4, 7, 8], "519052": 6, "592580": 6, "5e": 8, "6": 5, "60": 8, "6029": 8, "6159": 8, "619183": 6, "650m": 3, "7": [5, 7], "718": [2, 3], "7397": 8, "7689": 8, "8": [7, 8], "882645": 6, "8gb": 3, "9": [5, 7], "9067": 8, "9218": 8, "9616": 8, "999": 6, "A": [4, 8], "As": [], "But": [], "For": [1, 3, 4, 6, 8], "If": [1, 2], "In": [3, 4, 5, 6, 7, 8], "It": [], "No": 5, "One": 6, "That": [], "The": [1, 2, 4, 6, 8], "There": 1, "These": [3, 7], "To": [1, 8], "With": [], "_": [6, 8], "__getitem__": 7, "_global_": 8, "_mask_input": 5, "_target_": 8, "_transform_fn": 7, "_util": [5, 6], "a1": 7, "aa": 5, "about": [], "acceler": [1, 6, 8], "accept": [], "accordingli": 6, "accumul": 8, "accumulate_grad_batch": 8, "accuraci": 3, "acdefghiklmnpqrstvwi": 8, "acid": [5, 8], "activ": 1, "actual": [5, 8], "actual_diff": 6, "actual_differ": 6, "add": [6, 7, 8], "add_": [], "addit": [1, 4], "adjust": 5, "advanc": 4, "affect": 5, "affin": 6, "after": 8, "against": 6, "align": [], "all": [2, 6], "all_concept": 4, "all_pr": 6, "allclos": 6, "allow": [3, 5], "alpha": [5, 6, 7, 8], "also": 7, "amino": [5, 8], "amino_acid": [6, 8], "amino_acid_token": 6, "aminoacidtokenizerfast": [4, 6], "an": [1, 3], "analysi": 5, "ani": [], "annot": 7, "antibody_pool": 6, "append": [4, 5, 6, 7, 8], "applic": 6, "approach": [1, 2], "appropri": 4, "ar": [1, 2, 3, 4, 6], "architectur": [6, 8], "arg": 6, "argmax": 5, "argsort": [5, 7], "arndceqghilkmfpstwyv": 6, "arndcqeghilkmfpstwyv": 5, "around": 4, "arrai": [5, 7], "asalam91": [1, 3, 4, 5, 7], "ascend": 6, "aspirin": 4, "asset": 4, "atgcgatcgatcgatcg": 4, "atol": 6, "attent": [4, 7, 8], "attention_mask": [3, 4, 5, 7, 8], "attention_probs_dropout_prob": 6, "attn": 1, "attribut": 6, "attributeerror": 6, "auditori": [], "australia": [], "auto": [3, 6, 7, 8], "automat": 1, "autonotebook": [6, 7, 8], "avail": [1, 3, 5, 7], "averag": 8, "awcptnkratscpnqlihfmrnqwniqhtlqfydeiqmfdgcadnh": 6, "ax": [], "axhlin": 5, "aya": 0, "b": 8, "base": [3, 4, 6], "basic": 8, "batch": [4, 6, 8], "batch_max_len": 4, "batch_siz": [6, 8], "batch_token": 4, "batteri": 2, "begin": [], "beignet": 2, "being": 1, "bert": 3, "best": [1, 3, 8], "beta": [5, 7], "beta1": 6, "beta2": 6, "better": 6, "between": 6, "bia": 7, "bib": [], "bibliographi": [], "bibtex": [], "bidirect": 3, "bin": 1, "bind": 6, "bio": 5, "biochem": [], "biolog": [3, 4, 5], "biophys": [], "biopython": [1, 5], "block": [], "book": [], "both": [4, 6], "bottleneck": 2, "box": [], "break": [4, 6], "brian": [], "brisban": [], "build": [4, 5], "built": 2, "c": [0, 4], "c1c": 4, "cach": 5, "calcul": [5, 6, 7, 8], "calculate_gravi": 5, "calculate_helix_fract": 5, "call": [5, 6, 7], "callback": [6, 8], "campaign": 2, "can": [1, 3, 4, 7, 8], "candid": 6, "candidate_heavi": 6, "candidate_light": 6, "candidate_pkd": 6, "candidate_pool": 6, "capabl": 2, "care": 8, "case": [3, 4], "cb": 2, "cb_lobster_150m": 3, "cb_lobster_24m": [3, 5, 7], "cb_lobster_3b": 3, "cb_lobster_650m": 3, "cb_model": 7, "cb_model_nam": 7, "cbm": 3, "cc": 4, "cd": 1, "cell": [5, 6, 7], "chain": 6, "check": [1, 5, 6, 7], "checkpoint": [3, 6, 8], "checkpoint_callback": 8, "chemic": 4, "choic": [6, 8], "choos": [1, 3, 5, 7], "christoph": [], "cite": 2, "ckpt": [3, 6, 8], "cl": [3, 4, 7], "class": 3, "classif": [3, 7], "clean": 5, "cli": 8, "clm": 3, "clone": [1, 5], "cls_embed": [3, 7], "cluster": 7, "cm": [], "cmap": [], "cn": 8, "code": [1, 2, 8], "cognit": [], "cold": [], "color": 5, "column": [6, 8], "com": 1, "combin": [3, 6], "combined_data": 6, "combined_df": 6, "come": 4, "command": 8, "commonmark": [], "compat": [1, 4], "complet": [3, 8], "complex": 8, "comput": [3, 8], "concept": 2, "concept1_idx": 5, "concept1_nam": 5, "concept2_idx": 5, "concept2_nam": 5, "concept_idx": 5, "concept_index": 5, "concept_indic": 5, "concept_nam": [5, 7], "concepts_list": 5, "confer": [], "config": 8, "configur": 4, "consid": [3, 8], "constraint": 3, "content": [], "continu": 8, "contributor": 2, "control": [2, 3, 5], "convert": [4, 7], "coolwarm": [], "core": [1, 3], "correct": 1, "correl": 6, "correspond": [4, 6], "cortex": 2, "cover": 8, "cpu": [5, 6, 7], "creat": [1, 4, 5], "critic": 4, "csv": 8, "cuda": [1, 5, 7], "custom_lin": [], "cvglkavlcpckcttkppekvwfrhcvaneccatyfkivwlrwqpl": 6, "cycler": [], "d": [], "dai": 8, "data": [2, 4], "datafram": [6, 8], "dataframelightningdatamodul": 8, "dataload": 6, "datamodul": 6, "dataset": [3, 4, 8], "ddp": 8, "de": [], "decod": [3, 5, 7], "decomposit": 7, "def": [4, 5, 6, 8], "default": 4, "defin": [6, 7], "demand": 2, "demonstr": [5, 7, 8], "dens": 7, "depend": [4, 8], "descript": 3, "design": [1, 2, 3, 4, 5, 6], "detail": [3, 4], "determin": 4, "develop": 1, "devic": [1, 5, 6, 7, 8], "df": [6, 8], "dict": 6, "dictconfig": 8, "differ": [3, 4, 5], "dim": 5, "dim_feedforward": 8, "dimens": 7, "direct": 6, "dirpath": [6, 8], "discoveri": 2, "disk": 1, "displai": [5, 6, 7], "distribut": 8, "dna": 4, "do": [], "do_lower_cas": 4, "doc": [6, 7, 8], "document": [6, 7, 8], "dollar": [], "don": 8, "down": 4, "downstream": [3, 7], "dreyer": 0, "dropout": 7, "drug": 2, "dryrun": 8, "dummi": 6, "duplic": 6, "dure": [1, 6, 8], "dyab_datamodul": 6, "dyab_model": 6, "e": [1, 5, 7, 8], "each": [3, 4, 5, 6, 7], "early_stop": 8, "earlystop": [6, 8], "easier": 4, "ecosystem": 2, "ed": 0, "edit": 3, "effect": 8, "element": 6, "elementwise_affin": 7, "els": [5, 7], "emb": [], "emb_layer_norm_aft": 7, "embed": [2, 3, 8], "embeddings_2d": 7, "en": [6, 7, 8], "enc": 4, "encod": [3, 4, 7], "encount": 1, "end": 4, "engin": 2, "ensur": [1, 5], "enumer": [5, 6, 7], "env": 1, "environ": 1, "eo": 4, "ep": [6, 7], "epoch": [6, 8], "eqkliseedlmamvkqtlnsnlqfihfiqklinsqislligklfkkfnariakisakeelrkhiaeqlnrevdyleakyakknreemrklekeisqikedlkktveslqakiqdlskkypgadakkmeeqrqqleeqknklqaeienllnsidhakklkeeiaqlqeeisqledeneklrrdienqkennklleeeltklqaensslrkelealterlqdlyeslklkdddavn": 5, "error": 5, "escap": [], "esm": 4, "etc": [], "eval": [5, 6, 7, 8], "evalu": [5, 7], "everi": 6, "evid": [], "examin": 6, "exampl": [6, 8], "except": 5, "execut": 8, "exp": 8, "expect": 6, "experi": 2, "explor": [3, 4], "exponenti": 8, "extend": [3, 6], "extens": [], "extract": 5, "extract_concept": 5, "f": [1, 5, 6, 7, 8], "fals": [4, 6, 7, 8], "fast": [1, 2], "faster": 8, "fastest": 3, "feedforward": 8, "few": 5, "fig": [], "figsiz": [5, 6, 7, 8], "figur": [5, 6, 7, 8], "fiigedlwawithytdhpsqtklvnancimgftvfemmrnedkqlneygkqhcefnqwddeeld": 8, "file": [1, 4, 7], "filenam": [6, 8], "filepath_or_buff": 8, "final": 8, "final_val_loss": 8, "fine": 2, "first": [5, 6, 7, 8], "fit": 6, "fit_transform": 7, "fix": [], "flash": 1, "flavor": [], "flexbert": 6, "follow": [1, 2, 3, 4], "font": 5, "fontsiz": [5, 7], "form": 6, "format": 6, "forward": 4, "found": [1, 6, 7, 8], "foundat": 2, "fraction": 5, "framework": 2, "freder": 0, "frei": [0, 2], "from": [1, 2, 3, 4, 5, 6, 7], "from_pretrain": 4, "frontier": [], "full": 1, "function": [5, 6], "fv_heavi": 6, "fv_light": 6, "g": 4, "gelu": 6, "geluactiv": 7, "genentech": 2, "gener": [2, 3, 5, 6, 7, 8], "generate_sample_data": 6, "generate_synthetic_data": 8, "generated_helix": 5, "generated_sequ": 5, "genom": 4, "get": [3, 5, 6, 7], "get_device_nam": 1, "ggwvpqlvsdenhiflwkkmmyyfdmgykwewychniynpaqktvc": 6, "git": 1, "github": [1, 6, 7, 8], "give": 6, "gpt": 3, "gpu": [3, 5, 7, 8], "gradient": [7, 8], "gravi": 5, "grid": [5, 6, 7, 8], "guid": 2, "h_len": 6, "ha": [1, 6], "halnvdwenlpcvikptiewmnifensqvfhpnrrnwfvwiradfa": 6, "handl": [4, 6], "happen": 8, "have": [1, 4, 7], "hdhpk14": [], "head": [3, 6, 8], "heavi": 6, "heavy_chain": 6, "heavy_length": 6, "heer": [], "held": 8, "helix": 5, "helix_fract": 5, "help": [], "hemoglobin": [5, 7], "here": 8, "heterogen": 7, "hidden": 8, "hidden_act": 6, "hidden_dim": 8, "hidden_dropout_prob": 6, "hidden_s": 6, "high": [3, 5], "high_helix_low_hydro": 5, "high_helix_low_hydro_gravi": 5, "high_helix_low_hydro_helix": 5, "higher": 6, "hmpisqtqfpqhysgwwvqnwiqtfnkmrnclgkqptdmwasmikr": 6, "hnrnp": 7, "hofmann": 0, "holdgraf": [], "holdgraf_evidence_2014": [], "hot": [], "hour": 8, "how": [5, 7, 8], "html": [6, 7, 8], "http": [1, 6, 7, 8], "human": [], "hydra": [1, 8], "hydro": 5, "hydrophob": 5, "hyperparamet": 8, "i": [1, 2, 4, 5, 6, 7, 8], "ident": 6, "idx": [5, 7], "ii": [], "illustr": 8, "iloc": [6, 8], "imag": [], "implement": [3, 4], "import": [1, 3, 4, 5, 6, 7, 8], "importlib": 4, "improv": 6, "in_featur": 7, "includ": [2, 4, 5], "index": [5, 8], "indic": [5, 7], "infer": [5, 7, 8], "inference_datamodul": 6, "inform": 6, "init": [], "initi": [6, 8], "inlin": [], "inner_dict": 7, "inplac": 7, "input": 5, "input_id": [3, 4, 5, 7, 8], "insert": [], "instal": 2, "instanti": 4, "instantiate_at_run": 8, "instruct": 2, "int": 5, "integ": 7, "integr": [2, 4], "interact": [], "intermedi": 7, "intermediate_act_fn": 7, "intermediate_s": 6, "intern": [], "interpret": [2, 3, 7], "interven": 5, "intervene_and_gener": 5, "intervention_valu": 5, "io": [6, 7, 8], "ion": [], "iprogress": [6, 7, 8], "ipynb": [], "ipywidget": [6, 7, 8], "is_avail": [1, 5, 7], "is_ident": 6, "ismail": 0, "issu": 1, "item": 6, "iterrow": 6, "its": [2, 6], "jen": 0, "join": [5, 6, 8], "joren": 0, "joseph": 0, "jupyt": [6, 7, 8], "jupyterbook": [], "jupytext": [], "just": 8, "k": 7, "karina": 0, "keep": [], "kei": [7, 8], "kernel": [], "kind": [], "kleinhenz": 0, "knight": [], "l2": 8, "l_len": 6, "la_": [], "lab": 2, "label": [5, 7, 8], "languag": [4, 7, 8], "larger": 8, "last": [5, 6, 7, 8], "layer": [3, 7, 8], "layer_norm": 7, "layernorm": 7, "lbster": 1, "learn": [3, 6, 8], "learning_r": [6, 8], "legend": [5, 8], "len": [4, 5, 6, 8], "length": [4, 6, 8], "let": [5, 6, 7, 8], "lib": [6, 7, 8], "librari": [2, 5, 7, 8], "light": 6, "light_chain": 6, "light_length": 6, "lightn": [1, 6, 8], "like": [1, 6], "likelihood": 8, "limit": 3, "line": [5, 6, 7, 8], "line2d": [], "linear": 7, "linestyl": 5, "linewidth": 5, "link": 3, "linspac": [], "linux": 1, "list": [1, 5, 6, 7], "littl": 8, "live": 2, "ll": [3, 4, 5, 6, 7, 8], "llm": 3, "lm_head": 7, "lmbase": 7, "lmbaseattent": 7, "lmbaseembed": 7, "lmbaseencod": 7, "lmbaseformaskedlm": 7, "lmbaseintermedi": 7, "lmbaselay": 7, "lmbaselmhead": 7, "lmbasemodel": 7, "lmbaseoutput": 7, "lmbaseselfattent": 7, "lmbaseselfoutput": 7, "load": [1, 8], "load_from_checkpoint": [3, 6, 8], "loaded_model": 6, "loaded_pr": 6, "lobster": [1, 2, 3, 4, 5, 6, 7, 8], "lobster_150m": 3, "lobster_24m": [1, 3, 4, 7], "lobster_train": 8, "lobstercbmpmlm": [5, 7], "lobsterpmlm": [1, 4, 7, 8], "loc": 6, "log": 8, "log_every_n_step": [6, 8], "logger": 8, "logit": 5, "logspac": [], "longer": [6, 8], "look": 6, "loss": 8, "lot": [], "low": 5, "low_helix_high_hydro": 5, "low_helix_high_hydro_gravi": 5, "low_helix_high_hydro_helix": 5, "lower": 8, "lr": 6, "lw": [], "lysozym": 7, "mai": [4, 5], "maintain": [3, 5], "make": [1, 6, 7, 8], "mani": [], "manifold": 7, "manner": 5, "markdownfil": [], "markedli": [], "markers": 5, "markup": [], "mask": [4, 5, 7], "mask_token_id": 5, "masked_token": 5, "match": 6, "math": [], "matplotlib": [5, 6, 7, 8], "max": [4, 6], "max_epoch": [6, 8], "max_len": 8, "max_length": [4, 6, 8], "mbox": [], "md": [], "mean": 6, "meaning": 4, "meapaagaapppgpalgngvagaggeaaaapggggeaparkrgrpggdnhgpgreardgprerlgagpadagpgapgsqhpggrgrgggpglstlpgggpgpggfgplgfpmrgrggpgpggfgprggpgaagfptrgrgggpgpdgf": 7, "medium": 3, "memori": [3, 8], "method": 1, "metric": [6, 8], "mgm": 1, "mgmtoken": 4, "might": [1, 8], "min": [4, 6, 8], "min_len": 8, "mix": 8, "mixtur": 2, "mlm": 3, "mnifemlrideglrlkiykdtegyytigighlltkspslnaakseldkaigrntngvitkdeaeklfnqdvdaavrgilrnaklkpvydsldavrraalinmvfqmgetgvagftnslrmlqqkrwdeaavnlaksrwynqtpnrakrvittfrtgtwdayknl": 7, "modal": [1, 2, 4], "mode": [1, 5, 6, 7, 8], "model": 1, "model_config": 6, "model_max_length": 4, "model_nam": [5, 7], "model_path": 6, "model_typ": 6, "modelcheckpoint": [6, 8], "modeloutput": 7, "modif": 6, "modifi": 5, "modified_concept": 5, "modul": [5, 6, 8], "modular": 2, "modulelist": 7, "modulenotfounderror": 5, "molecul": [1, 2, 4], "molecular": [1, 2], "moment": 5, "monitor": [6, 8], "more": [3, 4, 8], "moreov": [], "most": [2, 5, 6, 7], "multi": [1, 2, 4, 8], "multi_concept_interven": 5, "multipl": [1, 4, 5], "multitask": 2, "must": 7, "mvhltpeeksavtalwgkvnvdevggealgrllvvypwtqrffesfgdlstpdavmgnpkvkahgkkvlgafsdglahldnlkgtfatlselhcdklhvdpenfrllgnvlvcvlahhfgkeftppvqaayqkvvagvanalahkyh": [5, 7], "mvlspadktnvkaawg": 4, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphf": 3, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphfdlshgsaqvkgh": 8, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphfdlshgsaqvkghgkkvadaltnavahvddmpnalsalsdlhahklrvdpvnfkllshcllvtlaahlpaeftpavhasldkflasvstvltskyr": [5, 7], "n": [], "n5": 8, "n_compon": 7, "n_head": 8, "n_layer": 8, "n_sampl": 8, "nadvanc": 8, "name": [5, 7, 8], "nathan": 0, "ncfrei": [6, 7, 8], "necessari": [4, 5, 6, 7, 8], "need": [1, 2, 6, 8], "neg": 8, "network": 8, "neurosci": [], "new": [1, 2, 5], "new_data": 6, "new_seq": 5, "new_sequ": 5, "new_token": 5, "nfor": 8, "nintervent": 5, "nmulti": 5, "nn": 6, "no_grad": [5, 6, 7], "none": 5, "norigin": 5, "normal": [4, 6], "note": [], "notebook": 8, "notebook_tqdm": [6, 7, 8], "novel": 2, "now": [5, 6, 7], "np": [5, 6, 7, 8], "nsimul": 8, "ntop": [5, 7], "nuclear": 7, "nucleotidetokenizerfast": 4, "num_attention_head": 6, "num_hidden_lay": 6, "num_sampl": 6, "num_work": [6, 8], "number": [5, 8], "numel": 1, "numer": 4, "numpi": [5, 6, 7, 8], "o": [4, 5, 8], "object": [2, 3, 6], "oc1": 4, "off": 7, "omegaconf": 8, "onc": 8, "one": [], "onli": [1, 3, 5], "open": [1, 2, 8], "oper": 1, "optim": [6, 8], "option": 8, "order": 6, "org": [], "origin": 6, "original_concept": 5, "original_gravi": 5, "original_helix": 5, "original_pr": 6, "other": [], "our": [6, 7], "out": 8, "out_featur": 7, "output": [3, 4, 5, 7], "overal": 5, "overview": [], "own": [6, 8], "p": [1, 7], "p_mask": 5, "packag": [1, 6, 7, 8], "pad": [4, 6, 8], "pad_token_id": [4, 6], "padded_enc": 4, "padded_encod": 4, "padding_idx": 7, "page": 3, "pair": 6, "pairs_data": 6, "pairs_df": 6, "pairwis": 6, "panda": [1, 5, 6, 7, 8], "paper": [2, 8], "paramet": [1, 3, 5, 6, 7, 8], "particularli": 6, "paslei": [], "pass": 4, "path": [3, 4, 8], "patienc": [6, 8], "pc1": 7, "pc2": 7, "pca": 7, "pd": [5, 6, 7, 8], "per": 8, "perform": [3, 5], "period": 2, "perplex": 8, "pip": [1, 5, 7, 8], "pipelin": [4, 8], "pkd": 6, "pkd_valu": 6, "pl": [6, 8], "platform": 1, "pleas": [1, 2, 6, 7, 8], "plmfold": 3, "plot": [5, 6, 7, 8], "plt": [5, 6, 7, 8], "pmlm_token": [4, 8], "pmlmconcepttokenizertransform": 4, "pmlmtoken": 4, "pmlmtokenizertransform": [7, 8], "pool": 6, "position_embed": 7, "post": [], "power": 5, "pre": [1, 2, 4, 5], "precis": 8, "pred": 6, "pred_diff": 6, "pred_token": 5, "predict": 5, "predict_binding_differ": 6, "predict_dataload": 6, "predicted_diff_ref_candid": 6, "predicted_differ": 6, "prefer": 1, "prepar": 6, "prepare_data": 6, "preprocess": 4, "prescient": [1, 2], "presenc": [], "present": 4, "pretrain": 6, "print": [1, 4, 5, 6, 7, 8], "problem": 2, "process": [1, 4, 5, 6, 7], "prop_cycl": [], "properli": [], "properti": [3, 5, 6], "protein": [2, 3, 4, 5, 6, 8], "proteinanalysi": 5, "protparam": 5, "provid": [3, 4, 5, 7], "pt": [3, 4, 5, 7, 8], "pure": 3, "purpos": [3, 6], "py": [6, 7, 8], "pyplot": [5, 6, 7, 8], "pyproject": 1, "python": 1, "python3": [6, 7, 8], "pytorch": [6, 8], "queri": 7, "quickli": 2, "r": [5, 6, 8], "r2": 6, "r2_score": 6, "ramsai": [], "randint": [6, 8], "randn": 8, "random": [6, 8], "rang": [6, 8], "rank_antibodi": 6, "ranked_candid": 6, "ranked_df": 6, "rate": 8, "raw": 4, "rcparam": [], "rdkit": 1, "read_csv": 8, "readm": 2, "readthedoc": [6, 7, 8], "real": [2, 6, 8], "recent": [5, 6, 7], "recogn": 1, "recommend": 1, "reduc": 7, "ref": 6, "ref_candidate_pr": 6, "refer": 6, "reference_antibodi": 6, "reflect": 2, "regress": [3, 6], "regressor_dropout": 6, "regressor_hidden_s": 6, "regressor_num_lay": 6, "regular": 8, "relationship": 6, "relev": 2, "remove_nul": 6, "render": [], "replac": 5, "repo": 1, "repositori": 1, "repres": 4, "represent": [3, 7], "reproduc": 6, "requir": 3, "research": 2, "resolv": 1, "resourc": [4, 8], "rest": [], "result": [4, 5, 6, 8], "results_df": 6, "resum": 8, "resume_from_checkpoint": 8, "return": [4, 5, 6, 7, 8], "return_attention_mask": 6, "return_tensor": [3, 4, 5, 7, 8], "rfrdtnmhqplvrpfvlntkpscveycnaeprntkwpksgftgpfw": 6, "ribonucleoprotein": 7, "right": 8, "rlhnhnrkihpgclrpegcswecsmcmtwgmyngrgmmaeysgash": 6, "rna": 4, "robert": [], "root_dir": 8, "rotary_embed": 7, "rotaryembed": 7, "row": 6, "run": [1, 8], "run_test": 8, "r\u00b2": 6, "same": 6, "sampl": [], "save": 8, "save_checkpoint": 6, "save_dir": 8, "save_last": 8, "save_top_k": [6, 8], "scatter": [6, 7], "schedul": 8, "scipi": 1, "score": 6, "scratch": 2, "seaborn": 5, "search": 3, "second": 6, "secondary_structure_fract": 5, "section": [3, 4], "see": [2, 5, 6, 7, 8], "seed": 6, "seed_everyth": 6, "select": 6, "self": 7, "selfi": [1, 4], "sep": 4, "separ": 4, "seq": [4, 5, 7, 8], "seq_concept": [5, 7], "seq_nam": [5, 7], "sequenc": [3, 4, 8], "sequence1": 6, "sequence1_data": 6, "sequence2": 6, "sequence2_data": 6, "sequence_idx": 5, "sequence_nam": 5, "sequtil": 5, "serv": [], "set": [5, 7, 8], "setup": 6, "sever": [3, 4, 7], "shape": [5, 6, 7], "sheet": 5, "should": 8, "show": [5, 6, 7, 8], "sign": [], "similar": 3, "simpl": 8, "simulate_training_process": 8, "simultan": 5, "singl": 5, "site": [6, 7, 8], "size": [3, 8], "sklearn": [6, 7], "slice": 7, "slight": [], "slower": 1, "small": 8, "smilestokenizerfast": 4, "sn": 5, "so": 6, "some": [1, 6, 7], "sort": 6, "sort_valu": 6, "sourc": [1, 2], "space": [1, 2], "span": [], "special": [], "specif": [4, 5], "speed": 3, "sphinx": [], "split": 6, "squeez": [5, 7], "stabl": [6, 7, 8], "stage": 6, "stand": [], "standard": [2, 4, 8], "start": [4, 7], "starter": [], "state": [], "step": 4, "still": 1, "store": 6, "strategi": 2, "string": 4, "structur": 5, "style": 4, "subplot": [], "successfulli": 1, "suffici": 1, "sum": 1, "support": [2, 4], "supported_biopython_concept": 5, "sure": [1, 7, 8], "swap": 6, "swissprot": 3, "syntax": [], "synthet": [6, 8], "synthetic_protein": 8, "system": 1, "t": [4, 8], "t4": 7, "take": 5, "target": [5, 6], "target1": 6, "target2": 6, "task": [3, 4, 6, 7], "taylor": 0, "templat": 5, "tensor": [4, 5], "tensorboardlogg": 8, "termin": 8, "test": [6, 8], "test_result": 6, "tex": [], "text": [], "than": 6, "thei": [3, 6], "them": 4, "therapeut": 2, "thi": [1, 2, 3, 4, 5, 7, 8], "thing": [], "those": [], "through": [2, 4, 6], "tiftwytfhgrmqhlfdmrclewidhertcekiegrkmqimtfrla": 6, "tight_layout": [5, 6, 7], "time": 8, "titl": [5, 6, 7, 8], "to_csv": 8, "to_tupl": 7, "toi": 6, "token": [3, 5, 6, 7, 8], "tokenizer_dir": 8, "tokenizertransform": [4, 6], "toml": 1, "tool": 5, "top": [5, 6], "top_concept_indic": [5, 7], "torch": [1, 4, 5, 6, 7, 8], "total": 5, "tqdm": [6, 7, 8], "tqdmwarn": [6, 7, 8], "traceback": [5, 6, 7], "tradeoff": 3, "train": [1, 2, 4, 5], "train_config": 8, "train_dataload": 6, "train_loss": 8, "trainer": [6, 8], "transform": [1, 6, 7, 8], "transform_fn": [6, 8], "treat": [], "tropomyosin": 5, "true": [3, 4, 5, 6, 7, 8], "truncat": [4, 6, 8], "try": 5, "tsne": 7, "tune": [2, 8], "tupl": [6, 7], "turn": [5, 7], "tutori": [5, 7, 8], "two": 5, "type": 3, "typeerror": 7, "typic": [4, 8], "u": 4, "understand": 8, "uniref50": 3, "unk": 4, "unknown": 4, "up": 8, "updat": [2, 6, 7, 8], "us": [2, 3, 5], "usag": 8, "user": [6, 7, 8], "user_instal": [6, 7, 8], "util": [7, 8], "v": 3, "val": [6, 8], "val_check_interv": 8, "val_dataload": 6, "val_loss": [6, 8], "valid": [5, 8], "valid_aa": 5, "valu": [3, 4, 5, 6, 7], "valuabl": 6, "variabl": 4, "variat": [], "variou": 7, "ve": [5, 6, 7, 8], "venv": [1, 6, 7, 8], "verifi": 6, "version": [1, 5], "vhnvlerqwrtlkyqveatlwtqtvhtvgtqamyytmsgywafypw": 6, "virtual": 1, "vocab_s": 6, "w": 8, "wagstaff": 0, "wai": 1, "wandb": 1, "want": [2, 6, 8], "warmup": 8, "warmup_step": 8, "we": [3, 4, 5, 6, 7, 8], "week": 8, "weight": 3, "weight_decai": [6, 8], "welcom": 2, "well": 6, "wendi": [], "what": [6, 8], "when": 3, "where": 6, "wherea": [], "whether": [], "which": [1, 2, 3, 6], "while": [3, 5], "without": 1, "word_embed": 7, "work": [1, 2], "worker": 6, "world": 2, "would": [6, 8], "wrapper": 4, "write": 8, "written": [], "x": 7, "xlabel": [5, 6, 7, 8], "y": 5, "y1": 6, "y2": 6, "yaml": 8, "yattnkelngffirfhngsrekcrscpkdplsefwklmlsppdlyp": 6, "ylabel": [5, 6, 7, 8], "yml": 1, "you": [1, 2, 4, 5, 6, 7, 8], "your": [1, 6], "zadorozhni": 0, "zip": [5, 6], "\u03b1": [5, 7], "\u03b2": [5, 7]}, "titles": ["Contributors", "Installation", "LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation \ud83e\udd9e", "LBSTER Models Overview", "Tokenization in LBSTER", "Concept Interventions with CB-LBSTER", "DyAb Model: Training and Inference Tutorial", "Embedding Extraction with LBSTER", "Training a LBSTER Model from Scratch"], "titleterms": {"1": [3, 4, 6, 8], "10": 6, "2": [3, 4, 6, 8], "3": [3, 4, 6, 8], "4": [3, 4, 6, 8], "5": [4, 6, 8], "6": [6, 8], "7": [6, 8], "8": 6, "9": 6, "acid": 4, "actual": 6, "add": [], "advanc": 8, "amino": 4, "an": [], "analyz": [5, 7], "antibodi": 6, "architectur": 3, "awar": 4, "basic": [3, 4], "biolog": 2, "block": [], "bottleneck": [3, 5, 7], "causal": 3, "cb": 5, "cell": [], "citat": 2, "code": [], "concept": [3, 4, 5, 7], "conclus": [5, 6, 7, 8], "conda": 1, "configur": 8, "content": [], "contribut": 2, "contributor": 0, "creat": [6, 8], "custom": 4, "data": [6, 8], "dataframelightningdatamodul": 6, "dataset": 6, "defin": 5, "demonstr": 6, "depend": 1, "differ": 6, "direct": [], "dyab": 6, "dyabdataframelightningdatamodul": 6, "dyabmodel": 6, "effect": 5, "embed": 7, "evalu": [6, 8], "evolutionari": 2, "exampl": [3, 5], "extract": 7, "file": 8, "from": 8, "get": 2, "gpu": 1, "guid": 3, "how": 6, "i": [], "infer": [3, 6], "instal": [1, 5, 7, 8], "intervent": 5, "languag": [2, 3], "lbster": [2, 3, 4, 5, 7, 8], "learn": [], "load": [3, 5, 6, 7], "lobstercbmpmlm": 3, "lobsterpclm": 3, "lobsterplmfold": 3, "lobsterpmlm": 3, "mamba": 1, "markdown": [], "mask": 3, "metadata": [], "mgm": 4, "model": [2, 3, 4, 5, 6, 7, 8], "more": [], "multi": 5, "myst": [], "new": 6, "notebook": 6, "nucleotid": 4, "option": 1, "origin": 5, "output": [], "overview": 3, "perform": 6, "pmlm": 4, "pre": [3, 7], "predict": [3, 6], "prepar": 8, "process": 8, "product": 8, "protein": 7, "quickli": [], "rank": 6, "represent": 2, "role": [], "sampl": [5, 6, 7], "save": 6, "scratch": 8, "select": 3, "sequenc": [2, 5, 6, 7], "set": 6, "setup": [5, 7, 8], "simul": 8, "size": 4, "smile": 4, "special": 4, "start": 2, "step": 8, "strategi": 8, "structur": 3, "support": 1, "thi": 6, "token": 4, "top": 7, "train": [3, 6, 7, 8], "transform": [2, 4], "troubleshoot": 1, "tutori": 6, "type": 4, "up": 6, "us": [1, 4, 6, 7, 8], "usag": 3, "uv": 1, "v": 6, "verifi": 1, "visual": [6, 7], "vocabulari": 4, "what": [], "workflow": 4, "yaml": [], "your": 8}})