Search.setIndex({"alltitles": {"1. Amino Acid Tokenizer": [[4, "amino-acid-tokenizer"]], "1. Masked Language Models (LobsterPMLM)": [[3, "masked-language-models-lobsterpmlm"]], "2. Concept Bottleneck Models (LobsterCBMPMLM)": [[3, "concept-bottleneck-models-lobstercbmpmlm"]], "2. Nucleotide Tokenizer": [[4, "nucleotide-tokenizer"]], "3. Causal Language Models (LobsterPCLM)": [[3, "causal-language-models-lobsterpclm"]], "3. SMILES Tokenizer": [[4, "smiles-tokenizer"]], "4. PMLM Tokenizer": [[4, "pmlm-tokenizer"]], "4. Structure Prediction Models (LobsterPLMFold)": [[3, "structure-prediction-models-lobsterplmfold"]], "5. MGM Tokenizer": [[4, "mgm-tokenizer"]], "Advanced: Training Strategies for Production Models": [[7, "advanced-training-strategies-for-production-models"]], "Analyzing Original Concepts": [[5, "analyzing-original-concepts"]], "Analyzing Top Concepts": [[6, "analyzing-top-concepts"]], "Analyzing the Effects of Interventions": [[5, "analyzing-the-effects-of-interventions"]], "Basic Tokenizer Transform": [[4, "basic-tokenizer-transform"]], "Basic inference:": [[3, "basic-inference"]], "Citations": [[2, "citations"]], "Concept Bottleneck Models": [[3, "concept-bottleneck-models"]], "Concept Intervention": [[5, "concept-intervention"]], "Concept Interventions with CB-LBSTER": [[5, null]], "Concept-aware Tokenizer Transform": [[4, "concept-aware-tokenizer-transform"]], "Conclusion": [[5, "conclusion"], [6, "conclusion"], [7, "conclusion"]], "Contributions": [[2, "contributions"]], "Contributors": [[0, null]], "Custom Tokenization Workflows": [[4, "custom-tokenization-workflows"]], "Define Sample Sequences": [[5, "define-sample-sequences"]], "Dependencies": [[1, "dependencies"]], "Embedding Extraction with LBSTER": [[6, null]], "Extracting Embeddings": [[6, "extracting-embeddings"]], "GPU Support": [[1, "gpu-support"]], "Getting started": [[2, "getting-started"]], "Installation": [[1, null]], "Installing Optional Dependencies": [[1, "installing-optional-dependencies"]], "Intervention Examples": [[5, "intervention-examples"]], "LBSTER Models Overview": [[3, null]], "LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation \ud83e\udd9e": [[2, null]], "Loading a Concept Bottleneck Model": [[5, "loading-a-concept-bottleneck-model"]], "Loading a Pre-trained Model": [[6, "loading-a-pre-trained-model"]], "Loading a pre-trained model:": [[3, "loading-a-pre-trained-model"]], "Masked Language Models": [[3, "masked-language-models"]], "Model Architectures": [[3, "model-architectures"]], "Model Selection Guide": [[3, "model-selection-guide"]], "Multi-Concept Intervention": [[5, "multi-concept-intervention"]], "Pre-trained Models": [[3, "pre-trained-models"]], "Sample Protein Sequences": [[6, "sample-protein-sequences"]], "Setup and Installation": [[5, "setup-and-installation"], [6, "setup-and-installation"], [7, "setup-and-installation"]], "Special Tokens": [[4, "special-tokens"]], "Step 1: Prepare Your Data": [[7, "step-1-prepare-your-data"]], "Step 2: Create a Configuration File": [[7, "step-2-create-a-configuration-file"]], "Step 3: Model Configuration": [[7, "step-3-model-configuration"]], "Step 4: Training Process": [[7, "step-4-training-process"]], "Step 5: Simulated Training Process": [[7, "step-5-simulated-training-process"]], "Step 6: Model Evaluation": [[7, "step-6-model-evaluation"]], "Step 7: Using Your Trained Model": [[7, "step-7-using-your-trained-model"]], "Tokenization in LBSTER": [[4, null]], "Tokenizer Transforms": [[4, "tokenizer-transforms"]], "Tokenizer Types": [[4, "tokenizer-types"]], "Training a LBSTER Model from Scratch": [[7, null]], "Troubleshooting": [[1, "troubleshooting"]], "Usage Examples": [[3, "usage-examples"]], "Using Concept Bottleneck Models": [[6, "using-concept-bottleneck-models"]], "Using Tokenizers with Models": [[4, "using-tokenizers-with-models"]], "Using mamba or conda": [[1, "using-mamba-or-conda"]], "Using uv": [[1, "using-uv"]], "Verifying Installation": [[1, "verifying-installation"]], "Visualizing Embeddings": [[6, "visualizing-embeddings"]], "Vocabulary Sizes": [[4, "vocabulary-sizes"]]}, "docnames": ["contributors", "installation", "intro", "models/overview", "tokenization/overview", "tutorials/concept_interventions", "tutorials/embedding_extraction", "tutorials/training_from_scratch"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["contributors.md", "installation.md", "intro.md", "models/overview.md", "tokenization/overview.md", "tutorials/concept_interventions.ipynb", "tutorials/embedding_extraction.ipynb", "tutorials/training_from_scratch.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 6, 7], "0": [1, 3, 4, 5, 6, 7], "01": 7, "1": [5, 6], "10": [1, 5, 6, 7], "100": [6, 7], "1000": 7, "100k": 7, "12": [1, 4, 5, 6], "128": 7, "14": [5, 6], "15": 7, "150m": 3, "16": 7, "16gb": 3, "19680801": [], "1e": 7, "2": [5, 6], "20": 4, "200": 7, "2014": [], "24": [1, 7], "24gb": 3, "24m": [3, 5, 6], "25": 5, "256": 7, "2f": 7, "3": [1, 5, 6], "30": 4, "33": 4, "35": 7, "3b": 3, "4": 1, "40": 7, "4f": [5, 6, 7], "4gb": 1, "5": [5, 6], "50": [5, 7], "512": [4, 7], "5e": 7, "6": 5, "60": 7, "650m": 3, "7": 5, "718": [2, 3], "8": [6, 7], "8gb": 3, "9": 5, "A": [4, 7], "As": [], "But": [], "For": [1, 3, 4, 7], "If": [1, 2], "In": [3, 4, 5, 6, 7], "It": [], "No": [5, 6, 7], "That": [], "The": [1, 2, 4, 7], "There": 1, "These": [3, 6], "To": [1, 7], "With": [], "_": 7, "_global_": 7, "_mask_input": 5, "_target_": 7, "_util": 5, "a1": 6, "aa": 5, "about": [], "acceler": [1, 7], "accept": [], "accumul": 7, "accumulate_grad_batch": 7, "accuraci": 3, "acdefghiklmnpqrstvwi": 7, "acid": [5, 7], "activ": 1, "actual": [5, 7], "add": [6, 7], "add_": [], "addit": [1, 4], "adjust": 5, "advanc": 4, "affect": 5, "after": 7, "align": [], "all": 2, "all_concept": 4, "allow": [3, 5], "alpha": [5, 6, 7], "also": 6, "amino": [5, 7], "amino_acid": 7, "aminoacidtokenizerfast": 4, "an": [1, 3], "analysi": 5, "ani": [], "annot": 6, "append": [4, 5, 6, 7], "approach": [1, 2], "appropri": 4, "ar": [1, 2, 3, 4], "architectur": 7, "argmax": 5, "argsort": [5, 6], "arndcqeghilkmfpstwyv": 5, "around": 4, "arrai": [5, 6], "asalam91": [1, 3, 4, 5, 6], "aspirin": 4, "asset": 4, "atgcgatcgatcgatcg": 4, "attent": [4, 7], "attention_mask": [3, 4, 5, 6, 7], "attn": 1, "auditori": [], "australia": [], "auto": [3, 7], "automat": 1, "avail": [1, 3, 5, 6], "averag": 7, "ax": [], "axhlin": 5, "aya": 0, "b": 7, "base": [3, 4], "basic": 7, "batch": [4, 7], "batch_max_len": 4, "batch_siz": 7, "batch_token": 4, "batteri": 2, "begin": [], "beignet": 2, "being": 1, "bert": 3, "best": [1, 3, 7], "beta": [5, 6], "bib": [], "bibliographi": [], "bibtex": [], "bidirect": 3, "bin": 1, "bio": 5, "biochem": [], "biolog": [3, 4, 5], "biophys": [], "biopython": [1, 5], "block": [], "book": [], "both": 4, "bottleneck": 2, "box": [], "break": 4, "brian": [], "brisban": [], "build": 4, "built": 2, "c": [0, 4], "c1c": 4, "calcul": [5, 6, 7], "calculate_gravi": 5, "calculate_helix_fract": 5, "call": [5, 6, 7], "callback": 7, "campaign": 2, "can": [1, 3, 4, 6, 7], "capabl": 2, "care": 7, "case": [3, 4], "cb": 2, "cb_lobster_150m": 3, "cb_lobster_24m": [3, 5, 6], "cb_lobster_3b": 3, "cb_lobster_650m": 3, "cb_model": 6, "cb_model_nam": 6, "cbm": 3, "cc": 4, "cd": 1, "cell": [5, 6, 7], "check": [1, 5, 6], "checkpoint": [3, 7], "checkpoint_callback": 7, "chemic": 4, "choic": 7, "choos": [1, 3, 5, 6], "christoph": [], "cite": 2, "ckpt": [3, 7], "cl": [3, 4, 6], "class": 3, "classif": [3, 6], "clean": 5, "cli": 7, "clm": 3, "clone": [1, 5], "cls_embed": [3, 6], "cluster": 6, "cm": [], "cmap": [], "cn": 7, "code": [1, 2, 7], "cognit": [], "cold": [], "color": 5, "column": 7, "com": 1, "combin": 3, "come": 4, "command": 7, "commonmark": [], "compat": [1, 4], "complet": [3, 7], "complex": 7, "comput": [3, 7], "concept": 2, "concept1_idx": 5, "concept1_nam": 5, "concept2_idx": 5, "concept2_nam": 5, "concept_idx": 5, "concept_index": 5, "concept_indic": 5, "concept_nam": [5, 6], "concepts_list": 5, "confer": [], "config": 7, "configur": 4, "consid": [3, 7], "constraint": 3, "content": [], "continu": 7, "contributor": 2, "control": [2, 3, 5], "convert": [4, 6], "coolwarm": [], "core": [1, 3], "correct": 1, "correspond": 4, "cortex": 2, "cover": 7, "cpu": [5, 6], "creat": [1, 4, 5], "critic": 4, "csv": 7, "cuda": [1, 5, 6], "custom_lin": [], "cycler": [], "d": [], "dai": 7, "data": [2, 4], "datafram": 7, "dataframelightningdatamodul": 7, "dataset": [3, 4, 7], "ddp": 7, "de": [], "decod": [3, 5], "decomposit": 6, "def": [4, 5, 7], "default": 4, "defin": 6, "demand": 2, "demonstr": [5, 6, 7], "depend": [4, 7], "descript": 3, "design": [1, 2, 3, 4, 5], "detail": [3, 4], "determin": 4, "develop": 1, "devic": [1, 5, 6, 7], "df": 7, "dictconfig": 7, "differ": [3, 4, 5], "dim": 5, "dim_feedforward": 7, "dimens": 6, "direct": [], "dirpath": 7, "discoveri": 2, "disk": 1, "displai": [5, 6], "distribut": 7, "dna": 4, "do": [], "do_lower_cas": 4, "document": [], "dollar": [], "don": 7, "down": 4, "downstream": [3, 6], "dreyer": 0, "drug": 2, "dryrun": 7, "dure": [1, 7], "e": [1, 5, 6, 7], "each": [3, 4, 5, 6], "early_stop": 7, "earlystop": 7, "easier": 4, "ecosystem": 2, "ed": 0, "edit": 3, "effect": 7, "els": [5, 6], "emb": [], "embed": [2, 3, 7], "embeddings_2d": 6, "enc": 4, "encod": [3, 4], "encount": 1, "end": 4, "engin": 2, "ensur": [1, 5], "enumer": [5, 6], "env": 1, "environ": 1, "eo": 4, "epoch": 7, "eqkliseedlmamvkqtlnsnlqfihfiqklinsqislligklfkkfnariakisakeelrkhiaeqlnrevdyleakyakknreemrklekeisqikedlkktveslqakiqdlskkypgadakkmeeqrqqleeqknklqaeienllnsidhakklkeeiaqlqeeisqledeneklrrdienqkennklleeeltklqaensslrkelealterlqdlyeslklkdddavn": 5, "error": 5, "escap": [], "esm": 4, "etc": [], "eval": [5, 6, 7], "evalu": [5, 6], "evid": [], "exampl": 7, "except": 5, "execut": 7, "exp": 7, "experi": 2, "explor": [3, 4], "exponenti": 7, "extend": 3, "extens": [], "extract": 5, "extract_concept": 5, "f": [1, 5, 6, 7], "fals": [4, 7], "fast": [1, 2], "faster": 7, "fastest": 3, "feedforward": 7, "few": 5, "fig": [], "figsiz": [5, 6, 7], "figur": [5, 6, 7], "file": [1, 4], "filenam": 7, "filepath_or_buff": 7, "final": 7, "final_val_loss": 7, "fine": 2, "first": [5, 6, 7], "fit_transform": 6, "fix": [], "flash": 1, "flavor": [], "follow": [1, 2, 3, 4], "fontsiz": [5, 6], "forward": 4, "found": 1, "foundat": 2, "fraction": 5, "framework": 2, "freder": 0, "frei": [0, 2], "from": [1, 2, 3, 4, 5, 6], "from_pretrain": 4, "frontier": [], "full": 1, "function": 5, "g": 4, "genentech": 2, "gener": [2, 3, 5, 7], "generate_synthetic_data": 7, "generated_helix": 5, "generated_sequ": 5, "genom": 4, "get": [3, 5, 6], "get_device_nam": 1, "git": 1, "github": 1, "gpt": 3, "gpu": [3, 5, 6, 7], "gradient": [6, 7], "gravi": 5, "grid": [5, 6, 7], "guid": 2, "ha": 1, "handl": 4, "happen": 7, "have": [1, 4, 6], "hdhpk14": [], "head": [3, 7], "heer": [], "held": 7, "helix": 5, "helix_fract": 5, "help": [], "hemoglobin": [5, 6], "here": 7, "heterogen": 6, "hidden": 7, "hidden_dim": 7, "high": [3, 5], "high_helix_low_hydro": 5, "high_helix_low_hydro_gravi": 5, "high_helix_low_hydro_helix": 5, "hnrnp": 6, "hofmann": 0, "holdgraf": [], "holdgraf_evidence_2014": [], "hot": [], "hour": 7, "how": [5, 6, 7], "html": [], "http": 1, "human": [], "hydra": [1, 7], "hydro": 5, "hydrophob": 5, "hyperparamet": 7, "i": [1, 2, 4, 5, 6, 7], "idx": [5, 6], "ii": [], "illustr": 7, "iloc": 7, "imag": [], "implement": [3, 4], "import": [1, 3, 4, 5, 6, 7], "importlib": 4, "includ": [2, 4, 5], "index": [5, 7], "indic": [5, 6], "infer": [5, 6, 7], "inform": [], "init": [], "initi": 7, "inlin": [], "input": 5, "input_id": [3, 4, 5, 6, 7], "insert": [], "instal": 2, "instanti": 4, "instantiate_at_run": 7, "instruct": 2, "int": 5, "integr": [2, 4], "interact": [], "intern": [], "interpret": [2, 3, 6], "interven": 5, "intervene_and_gener": 5, "intervention_valu": 5, "ion": [], "ipynb": [], "is_avail": [1, 5, 6], "ismail": 0, "issu": 1, "its": 2, "jen": 0, "join": [5, 7], "joren": 0, "joseph": 0, "jupyt": [], "jupyterbook": [], "jupytext": [], "just": 7, "karina": 0, "keep": [], "kei": 7, "kernel": [], "kind": [], "kleinhenz": 0, "knight": [], "l2": 7, "la_": [], "lab": 2, "label": [5, 6, 7], "languag": [4, 6, 7], "larger": 7, "last": [5, 6, 7], "layer": [3, 7], "lbster": 1, "learn": [3, 7], "learning_r": 7, "legend": [5, 7], "len": [4, 5, 7], "length": [4, 7], "let": [5, 6, 7], "librari": [2, 5, 6, 7], "lightn": [1, 7], "like": 1, "likelihood": 7, "limit": 3, "line": [5, 6, 7], "line2d": [], "linestyl": 5, "linewidth": 5, "link": 3, "linspac": [], "linux": 1, "list": [1, 5, 6], "littl": 7, "live": 2, "ll": [3, 4, 5, 6, 7], "llm": 3, "load": [1, 7], "load_from_checkpoint": [3, 7], "lobster": [1, 2, 3, 4, 5, 6, 7], "lobster_150m": 3, "lobster_24m": [1, 3, 4, 6], "lobster_train": 7, "lobstercbmpmlm": [5, 6], "lobsterpmlm": [1, 4, 6, 7], "log": 7, "log_every_n_step": 7, "logger": 7, "logit": 5, "logspac": [], "longer": 7, "loss": 7, "lot": [], "low": 5, "low_helix_high_hydro": 5, "low_helix_high_hydro_gravi": 5, "low_helix_high_hydro_helix": 5, "lower": 7, "lw": [], "lysozym": 6, "mai": 4, "maintain": [3, 5], "make": [1, 6, 7], "mani": [], "manifold": 6, "manner": 5, "markdownfil": [], "markedli": [], "markers": 5, "markup": [], "mask": [4, 5, 6], "mask_token_id": 5, "masked_token": 5, "math": [], "matplotlib": [5, 6, 7], "max": 4, "max_epoch": 7, "max_len": 7, "max_length": [4, 7], "mbox": [], "md": [], "mean": [], "meaning": 4, "meapaagaapppgpalgngvagaggeaaaapggggeaparkrgrpggdnhgpgreardgprerlgagpadagpgapgsqhpggrgrgggpglstlpgggpgpggfgplgfpmrgrggpgpggfgprggpgaagfptrgrgggpgpdgf": 6, "medium": 3, "memori": [3, 7], "method": 1, "metric": 7, "mgm": 1, "mgmtoken": 4, "might": [1, 7], "min": [4, 7], "min_len": 7, "mix": 7, "mixtur": 2, "mlm": 3, "mnifemlrideglrlkiykdtegyytigighlltkspslnaakseldkaigrntngvitkdeaeklfnqdvdaavrgilrnaklkpvydsldavrraalinmvfqmgetgvagftnslrmlqqkrwdeaavnlaksrwynqtpnrakrvittfrtgtwdayknl": 6, "modal": [1, 2, 4], "mode": [1, 5, 6, 7], "model": 1, "model_max_length": 4, "model_nam": [5, 6], "modelcheckpoint": 7, "modifi": 5, "modified_concept": 5, "modul": [5, 6, 7], "modular": 2, "modulenotfounderror": [5, 6, 7], "molecul": [1, 2, 4], "molecular": [1, 2], "monitor": 7, "more": [3, 4, 7], "moreov": [], "most": [2, 5, 6, 7], "multi": [1, 2, 4, 7], "multi_concept_interven": 5, "multipl": [1, 4, 5], "multitask": 2, "must": [], "mvhltpeeksavtalwgkvnvdevggealgrllvvypwtqrffesfgdlstpdavmgnpkvkahgkkvlgafsdglahldnlkgtfatlselhcdklhvdpenfrllgnvlvcvlahhfgkeftppvqaayqkvvagvanalahkyh": [5, 6], "mvlspadktnvkaawg": 4, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphf": 3, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphfdlshgsaqvkgh": 7, "mvlspadktnvkaawgkvgahageygaealermflsfpttktyfphfdlshgsaqvkghgkkvadaltnavahvddmpnalsalsdlhahklrvdpvnfkllshcllvtlaahlpaeftpavhasldkflasvstvltskyr": [5, 6], "n": [], "n5": 7, "n_compon": 6, "n_head": 7, "n_layer": 7, "n_sampl": 7, "nadvanc": 7, "name": [5, 6, 7], "nathan": 0, "necessari": [4, 5, 6, 7], "need": [1, 2, 7], "neg": 7, "network": 7, "neurosci": [], "new": [1, 2, 5], "new_seq": 5, "new_sequ": 5, "new_token": 5, "nfor": 7, "nintervent": 5, "nmulti": 5, "no_grad": [5, 6], "none": 5, "norigin": 5, "normal": 4, "note": [], "notebook": 7, "novel": 2, "now": [5, 6], "np": [5, 6, 7], "nsimul": 7, "ntop": [5, 6], "nuclear": 6, "nucleotidetokenizerfast": 4, "num_work": 7, "number": [5, 7], "numel": 1, "numer": 4, "numpi": [5, 6, 7], "o": [4, 5, 7], "object": [2, 3], "oc1": 4, "off": 6, "omegaconf": 7, "onc": 7, "one": [], "onli": [1, 3, 5], "open": [1, 2, 7], "oper": 1, "optim": 7, "option": 7, "org": [], "original_concept": 5, "original_gravi": 5, "original_helix": 5, "other": [], "our": 6, "out": 7, "output": [3, 4, 5, 6], "overal": 5, "overview": [], "own": 7, "p": 1, "p_mask": 5, "packag": [1, 7], "pad": [4, 7], "pad_token_id": 4, "padded_enc": 4, "padded_encod": 4, "page": 3, "panda": [1, 5, 6, 7], "paper": [2, 7], "paramet": [1, 3, 5, 6, 7], "paslei": [], "pass": 4, "path": [3, 4, 7], "patienc": 7, "pc1": 6, "pc2": 6, "pca": 6, "pd": [5, 6, 7], "per": 7, "perform": [3, 5], "period": 2, "perplex": 7, "pip": [1, 5, 6, 7], "pipelin": [4, 7], "pl": 7, "platform": 1, "pleas": [1, 2], "plmfold": 3, "plot": [5, 6, 7], "plt": [5, 6, 7], "pmlm_token": [4, 7], "pmlmconcepttokenizertransform": 4, "pmlmtoken": 4, "pmlmtokenizertransform": 7, "post": [], "power": 5, "pre": [1, 2, 4, 5], "precis": 7, "pred_token": 5, "predict": 5, "prefer": 1, "preprocess": 4, "prescient": [1, 2], "presenc": [], "present": 4, "print": [1, 4, 5, 6, 7], "problem": 2, "process": [1, 4, 5, 6], "prop_cycl": [], "properli": [], "properti": [3, 5], "protein": [2, 3, 4, 5, 7], "proteinanalysi": 5, "protparam": 5, "provid": [3, 4, 5, 6], "pt": [3, 4, 5, 6, 7], "pure": 3, "purpos": 3, "pyplot": [5, 6, 7], "pyproject": 1, "python": 1, "pytorch": 7, "quickli": 2, "r": [5, 7], "ramsai": [], "randint": 7, "randn": 7, "random": 7, "rang": 7, "rate": 7, "raw": 4, "rcparam": [], "rdkit": 1, "read_csv": 7, "readm": 2, "real": [2, 7], "recent": [5, 6, 7], "recogn": 1, "recommend": 1, "reduc": 6, "refer": [], "reflect": 2, "regress": 3, "regular": 7, "relev": 2, "render": [], "replac": 5, "repo": 1, "repositori": 1, "repres": 4, "represent": [3, 6], "reproduc": [], "requir": 3, "research": 2, "resolv": 1, "resourc": [4, 7], "rest": [], "result": [4, 5, 7], "resum": 7, "resume_from_checkpoint": 7, "return": [4, 5, 7], "return_tensor": [3, 4, 5, 6, 7], "ribonucleoprotein": 6, "right": 7, "rna": 4, "robert": [], "root_dir": 7, "run": [1, 7], "run_test": 7, "same": [], "sampl": [], "save": 7, "save_dir": 7, "save_last": 7, "save_top_k": 7, "scatter": 6, "schedul": 7, "scipi": 1, "scratch": 2, "seaborn": 5, "search": 3, "secondary_structure_fract": 5, "section": [3, 4], "see": [2, 5], "seed": [], "selfi": [1, 4], "sep": 4, "separ": 4, "seq": [4, 5, 6, 7], "seq_concept": [5, 6], "seq_nam": [5, 6], "sequenc": [3, 4, 7], "sequence_idx": 5, "sequence_nam": 5, "sequtil": 5, "serv": [], "set": [5, 6, 7], "sever": [3, 4, 6], "shape": [5, 6], "sheet": 5, "should": 7, "show": [5, 6, 7], "sign": [], "similar": 3, "simpl": 7, "simulate_training_process": 7, "simultan": 5, "singl": 5, "size": [3, 7], "sklearn": 6, "slight": [], "slower": 1, "small": 7, "smilestokenizerfast": 4, "sn": 5, "so": [], "some": [1, 6], "sourc": [1, 2], "space": [1, 2], "span": [], "special": [], "specif": [4, 5], "speed": 3, "sphinx": [], "squeez": [5, 6], "stand": [], "standard": [2, 4, 7], "start": [4, 6], "starter": [], "state": [], "step": 4, "still": 1, "store": [], "strategi": 2, "string": 4, "structur": 5, "style": 4, "subplot": [], "successfulli": 1, "suffici": 1, "sum": 1, "support": [2, 4], "supported_biopython_concept": 5, "sure": [1, 6, 7], "swissprot": 3, "syntax": [], "synthet": 7, "synthetic_protein": 7, "system": 1, "t": [4, 7], "t4": 6, "target": 5, "task": [3, 4, 6], "taylor": 0, "templat": 5, "tensor": [4, 5], "tensorboardlogg": 7, "termin": 7, "test": 7, "tex": [], "text": [], "thei": 3, "them": 4, "therapeut": 2, "thi": [1, 2, 3, 4, 5, 6, 7], "thing": [], "those": [], "through": [2, 4], "tight_layout": [5, 6], "time": 7, "titl": [5, 6, 7], "to_csv": 7, "token": [3, 5, 6, 7], "tokenizer_dir": 7, "tokenizertransform": 4, "toml": 1, "tool": 5, "top": 5, "top_concept_indic": [5, 6], "torch": [1, 4, 5, 6, 7], "total": 5, "traceback": [5, 6, 7], "tradeoff": 3, "train": [1, 2, 4, 5], "train_config": 7, "train_loss": 7, "trainer": 7, "transform": [1, 7], "transform_fn": 7, "treat": [], "tropomyosin": 5, "true": [3, 4, 5, 6, 7], "truncat": [4, 7], "try": 5, "tsne": 6, "tune": [2, 7], "turn": [5, 6], "tutori": [5, 6, 7], "two": 5, "type": 3, "typic": [4, 7], "u": 4, "understand": 7, "uniref50": 3, "unk": 4, "unknown": 4, "up": 7, "updat": 2, "us": [2, 3, 5], "usag": 7, "util": 7, "v": 3, "val": 7, "val_check_interv": 7, "val_loss": 7, "valid": [5, 7], "valid_aa": 5, "valu": [3, 4, 5, 6], "variabl": 4, "variat": [], "variou": 6, "ve": [5, 6, 7], "venv": 1, "version": [1, 5], "virtual": 1, "w": 7, "wagstaff": 0, "wai": 1, "wandb": 1, "want": [2, 7], "warmup": 7, "warmup_step": 7, "we": [3, 4, 5, 6, 7], "week": 7, "weight": 3, "weight_decai": 7, "welcom": 2, "well": [], "wendi": [], "what": 7, "when": 3, "wherea": [], "whether": [], "which": [1, 2, 3], "while": [3, 5], "without": 1, "work": [1, 2], "world": 2, "would": 7, "wrapper": 4, "write": 7, "written": [], "xlabel": [5, 6, 7], "y": 5, "yaml": 7, "ylabel": [5, 6, 7], "yml": 1, "you": [1, 2, 4, 5, 6, 7], "your": 1, "zadorozhni": 0, "zip": 5, "\u03b1": [5, 6], "\u03b2": [5, 6]}, "titles": ["Contributors", "Installation", "LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation \ud83e\udd9e", "LBSTER Models Overview", "Tokenization in LBSTER", "Concept Interventions with CB-LBSTER", "Embedding Extraction with LBSTER", "Training a LBSTER Model from Scratch"], "titleterms": {"1": [3, 4, 7], "2": [3, 4, 7], "3": [3, 4, 7], "4": [3, 4, 7], "5": [4, 7], "6": 7, "7": 7, "acid": 4, "add": [], "advanc": 7, "amino": 4, "an": [], "analyz": [5, 6], "architectur": 3, "awar": 4, "basic": [3, 4], "biolog": 2, "block": [], "bottleneck": [3, 5, 6], "causal": 3, "cb": 5, "cell": [], "citat": 2, "code": [], "concept": [3, 4, 5, 6], "conclus": [5, 6, 7], "conda": 1, "configur": 7, "content": [], "contribut": 2, "contributor": 0, "creat": 7, "custom": 4, "data": 7, "defin": 5, "depend": 1, "direct": [], "effect": 5, "embed": 6, "evalu": 7, "evolutionari": 2, "exampl": [3, 5], "extract": 6, "file": 7, "from": 7, "get": 2, "gpu": 1, "guid": 3, "i": [], "infer": 3, "instal": [1, 5, 6, 7], "intervent": 5, "languag": [2, 3], "lbster": [2, 3, 4, 5, 6, 7], "learn": [], "load": [3, 5, 6], "lobstercbmpmlm": 3, "lobsterpclm": 3, "lobsterplmfold": 3, "lobsterpmlm": 3, "mamba": 1, "markdown": [], "mask": 3, "metadata": [], "mgm": 4, "model": [2, 3, 4, 5, 6, 7], "more": [], "multi": 5, "myst": [], "notebook": [], "nucleotid": 4, "option": 1, "origin": 5, "output": [], "overview": 3, "pmlm": 4, "pre": [3, 6], "predict": 3, "prepar": 7, "process": 7, "product": 7, "protein": 6, "quickli": [], "represent": 2, "role": [], "sampl": [5, 6], "scratch": 7, "select": 3, "sequenc": [2, 5, 6], "setup": [5, 6, 7], "simul": 7, "size": 4, "smile": 4, "special": 4, "start": 2, "step": 7, "strategi": 7, "structur": 3, "support": 1, "token": 4, "top": 6, "train": [3, 6, 7], "transform": [2, 4], "troubleshoot": 1, "type": 4, "us": [1, 4, 6, 7], "usag": 3, "uv": 1, "verifi": 1, "visual": 6, "vocabulari": 4, "what": [], "workflow": 4, "yaml": [], "your": 7}})