# LBSTER: Language models for Biological Sequence Transformation and Evolutionary Representation ðŸ¦ž

`lobster` is a "batteries included" language model library for molecular foundation models.
* LBSTER is built for pre-training models quickly from scratch. This is most useful if you need to control the pre-training data mixture and embedding space, or want to experiment with novel pre-training objectives and fine-tuning strategies.
* LBSTER is a living, open-source library that will be periodically updated with new code and pre-trained models from the [Frey Lab](https://ncfrey.github.io/) at [Prescient Design, Genentech](https://www.gene.com/scientists/our-scientists/prescient-design). The Frey Lab works on real therapeutic molecule design problems and LBSTER models and capabilities reflect the demands of real-world drug discovery campaigns.
* LBSTER is built with [beignet](https://github.com/Genentech/beignet/tree/main), a standard library for biological research, and integrated with [cortex](https://github.com/prescient-design/cortex/tree/main), a modular framework for multitask modeling, guided generation, and multi-modal models.
* LBSTER supports biophysical and biochemical concepts; we have a concept-bottleneck protein language model, CB-LBSTER, which supports 718 concepts.

## Getting started
Follow the installation instructions in the `lobster` [README](https://github.com/prescient-design/lobster/tree/main?tab=readme-ov-file#install-).

## Citations
If you use `lobster` code and/or models, please cite the relevant papers in the `lobster` [README](https://github.com/prescient-design/lobster/tree/main?tab=readme-ov-file#citations-)

## Contributions
Contributions are welcome!

<!-- ```{tableofcontents}
``` -->
